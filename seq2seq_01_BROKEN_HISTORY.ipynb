{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!source activate jgrace1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/disk/ocean/jgrace\n"
     ]
    }
   ],
   "source": [
    "cd /disk/ocean/jgrace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "import socket\n",
    "hostname = socket.gethostname()\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence#, masked_cross_entropy\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from masked_cross_entropy import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "import pickle\n",
    "import subprocess\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_vectors_web_lg') # For the glove embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# set which GPU to use\n",
    "GPU_ID = 1\n",
    "torch.cuda.set_device(GPU_ID)\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use_CUDA=True\n",
      "current_device=1\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "print('Use_CUDA={}'.format(USE_CUDA))\n",
    "\n",
    "if USE_CUDA:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('current_device={}'.format(torch.cuda.current_device()))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul 10 16:20:36 2018       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 390.48                 Driver Version: 390.48                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX TIT...  Off  | 00000000:02:00.0 Off |                  N/A |\n",
      "| 41%   81C    P2   186W / 250W |  10119MiB / 12212MiB |     19%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX TIT...  Off  | 00000000:83:00.0 Off |                  N/A |\n",
      "| 22%   26C    P8    15W / 250W |     45MiB / 12212MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce GTX TIT...  Off  | 00000000:84:00.0 Off |                  N/A |\n",
      "| 22%   29C    P2    67W / 250W |    481MiB / 12212MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     35341      C   python                                      3712MiB |\n",
      "|    0     35519      C   python                                      5184MiB |\n",
      "|    0     38766      C   python                                       435MiB |\n",
      "|    0     39054      C   python                                       740MiB |\n",
      "|    2     40213      C   ...1365/miniconda3/envs/jgrace1/bin/python   435MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[38;5;27mcheckpoints\u001b[0m/  masked_cross_entropy.py  \u001b[38;5;27mpyrouge\u001b[0m/          \u001b[38;5;27mtensorboard-logs\u001b[0m/\n",
      "\u001b[38;5;27mdata\u001b[0m/         \u001b[38;5;27mmodels\u001b[0m/                  \u001b[38;5;27mrouge\u001b[0m/            \u001b[38;5;27mtestout\u001b[0m/\n",
      "\u001b[38;5;27mfiles2rouge\u001b[0m/  \u001b[38;5;27mopennmt_jgfork\u001b[0m/          \u001b[38;5;27mrouge-baselines\u001b[0m/\n",
      "\u001b[38;5;9mglove.6B.zip\u001b[0m  \u001b[38;5;27mOpenNMT-py\u001b[0m/              \u001b[38;5;27mscripts\u001b[0m/\n",
      "\u001b[38;5;27mglove_dir\u001b[0m/    \u001b[38;5;27m__pycache__\u001b[0m/             seq2seq_01.ipynb\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "from tqdm import tqdm\n",
    "from collections import Counter, namedtuple\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "PAD = 0\n",
    "BOS = 1\n",
    "EOS = 2\n",
    "UNK = 3\n",
    "\n",
    "MAX_SRC_DOC_LENGTH = 400\n",
    "MAX_TGT_DOC_LENGTH = 100\n",
    "MAX_DOC_LENGTH = 200\n",
    "\n",
    "class AttrDict(dict):\n",
    "    \"\"\" Access dictionary keys like attribute \n",
    "        https://stackoverflow.com/questions/4984647/accessing-dict-keys-like-an-attribute\n",
    "    \"\"\"\n",
    "    def __init__(self, *av, **kav):\n",
    "        dict.__init__(self, *av, **kav)\n",
    "        self.__dict__ = self\n",
    "\n",
    "class NMTDataset(Dataset):\n",
    "    def __init__(self, src_path, tgt_path, src_vocab=None, tgt_vocab=None, max_vocab_size=50000, share_vocab=True):\n",
    "        \"\"\" Note: If src_vocab, tgt_vocab is not given, it will build both vocabs.\n",
    "            Args: \n",
    "            - src_path, tgt_path: text file with tokenized sentences.\n",
    "            - src_vocab, tgt_vocab: data structure is same as self.build_vocab().\n",
    "        \"\"\"\n",
    "        print('='*100)\n",
    "        print('Dataset preprocessing log:')\n",
    "        \n",
    "        print('- Loading and tokenizing source sentences...')\n",
    "        self.src_sents = self.load_sents(src_path, sent_type = 'src')\n",
    "        print('- Loading and tokenizing target sentences...')\n",
    "        self.tgt_sents = self.load_sents(tgt_path, sent_type = 'tgt')\n",
    "        \n",
    "        if src_vocab is None or tgt_vocab is None:\n",
    "            print('- Building source counter...')\n",
    "            self.src_counter = self.build_counter(self.src_sents)\n",
    "            print('- Building target counter...')\n",
    "            self.tgt_counter = self.build_counter(self.tgt_sents)\n",
    "\n",
    "            if share_vocab:\n",
    "                print('- Building source vocabulary...')\n",
    "                self.src_vocab = self.build_vocab(self.src_counter + self.tgt_counter, max_vocab_size)\n",
    "                print('- Building target vocabulary...')\n",
    "                self.tgt_vocab = self.src_vocab\n",
    "            else:\n",
    "                print('- Building source vocabulary...')\n",
    "                self.src_vocab = self.build_vocab(self.src_counter, max_vocab_size)\n",
    "                print('- Building target vocabulary...')\n",
    "                self.tgt_vocab = self.build_vocab(self.tgt_counter, max_vocab_size)\n",
    "        else:\n",
    "            self.src_vocab = src_vocab\n",
    "            self.tgt_vocab = tgt_vocab\n",
    "            share_vocab = src_vocab == tgt_vocab\n",
    "                        \n",
    "        print('='*100)\n",
    "        print('Dataset Info:')\n",
    "        print('- Number of source sentences: {}'.format(len(self.src_sents)))\n",
    "        print('- Number of target sentences: {}'.format(len(self.tgt_sents)))\n",
    "        print('- Source vocabulary size: {}'.format(len(self.src_vocab.token2id)))\n",
    "        print('- Target vocabulary size: {}'.format(len(self.tgt_vocab.token2id)))\n",
    "        print('- Shared vocabulary: {}'.format(share_vocab))\n",
    "        print('='*100 + '\\n')\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.src_sents)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        src_sent = self.src_sents[index]\n",
    "        tgt_sent = self.tgt_sents[index]\n",
    "        src_seq = self.tokens2ids(src_sent, self.src_vocab.token2id, append_BOS=False, append_EOS=True)\n",
    "        tgt_seq = self.tokens2ids(tgt_sent, self.tgt_vocab.token2id, append_BOS=False, append_EOS=True)\n",
    "\n",
    "        return src_sent, tgt_sent, src_seq, tgt_seq\n",
    "    \n",
    "    def load_sents(self, file_path, sent_type):\n",
    "        sents = []\n",
    "        with codecs.open(file_path) as file:\n",
    "            for sent in tqdm(file.readlines()):\n",
    "                tokens = [token for token in sent.split()]\n",
    "                if sent_type == 'src':\n",
    "                    tokens_trunc = tokens[:MAX_SRC_DOC_LENGTH]\n",
    "                elif sent_type == 'tgt':\n",
    "                    tokens_trunc = tokens[:MAX_TGT_DOC_LENGTH]\n",
    "                else:\n",
    "                    print(\"FYI: no sentence type\")\n",
    "                    tokens_trunc = tokens[:MAX_DOC_LENGTH]\n",
    "                sents.append(tokens_trunc)\n",
    "        return sents\n",
    "    \n",
    "    def build_counter(self, sents):\n",
    "        counter = Counter()\n",
    "        for sent in tqdm(sents):\n",
    "            counter.update(sent)\n",
    "        return counter\n",
    "    \n",
    "    def build_vocab(self, counter, max_vocab_size):\n",
    "        vocab = AttrDict()\n",
    "        vocab.token2id = {'<PAD>': PAD, '<BOS>': BOS, '<EOS>': EOS, '<UNK>': UNK}\n",
    "        vocab.token2id.update({token: _id+4 for _id, (token, count) in tqdm(enumerate(counter.most_common(max_vocab_size)))})\n",
    "        vocab.id2token = {v:k for k,v in tqdm(vocab.token2id.items())}    \n",
    "        return vocab\n",
    "    \n",
    "    def tokens2ids(self, tokens, token2id, append_BOS=True, append_EOS=True):\n",
    "        seq = []\n",
    "        if append_BOS: seq.append(BOS)\n",
    "        seq.extend([token2id.get(token, UNK) for token in tokens])\n",
    "        if append_EOS: seq.append(EOS)\n",
    "        return seq\n",
    "    \n",
    "def collate_fn(data):\n",
    "    \"\"\"\n",
    "    Creates mini-batch tensors from (src_sent, tgt_sent, src_seq, tgt_seq).\n",
    "    We should build a custom collate_fn rather than using default collate_fn,\n",
    "    because merging sequences (including padding) is not supported in default.\n",
    "    Seqeuences are padded to the maximum length of mini-batch sequences (dynamic padding).\n",
    "    \n",
    "    Args:\n",
    "        data: list of tuple (src_sents, tgt_sents, src_seqs, tgt_seqs)\n",
    "        - src_sents, tgt_sents: batch of original tokenized sentences\n",
    "        - src_seqs, tgt_seqs: batch of original tokenized sentence ids\n",
    "    Returns:\n",
    "        - src_sents, tgt_sents (tuple): batch of original tokenized sentences\n",
    "        - src_seqs, tgt_seqs (variable): (max_src_len, batch_size)\n",
    "        - src_lens, tgt_lens (tensor): (batch_size)\n",
    "       \n",
    "    \"\"\"\n",
    "    def _pad_sequences(seqs):\n",
    "        lens = [len(seq) for seq in seqs]\n",
    "        padded_seqs = torch.zeros(len(seqs), max(lens)).long()\n",
    "        for i, seq in enumerate(seqs):\n",
    "            end = lens[i]\n",
    "            padded_seqs[i, :end] = torch.LongTensor(seq[:end])\n",
    "        return padded_seqs, lens\n",
    "\n",
    "    # Sort a list by *source* sequence length (descending order) to use `pack_padded_sequence`.\n",
    "    # The *target* sequence is not sorted <-- It's ok, cause `pack_padded_sequence` only takes\n",
    "    # *source* sequence, which is in the EncoderRNN\n",
    "    data.sort(key=lambda x: len(x[0]), reverse=True)\n",
    "\n",
    "    # Seperate source and target sequences.\n",
    "    src_sents, tgt_sents, src_seqs, tgt_seqs = zip(*data)\n",
    "    \n",
    "    # Merge sequences (from tuple of 1D tensor to 2D tensor)\n",
    "    src_seqs, src_lens = _pad_sequences(src_seqs)\n",
    "    tgt_seqs, tgt_lens = _pad_sequences(tgt_seqs)\n",
    "    \n",
    "    # (batch, seq_len) => (seq_len, batch)\n",
    "    src_seqs = src_seqs.transpose(0,1)\n",
    "    tgt_seqs = tgt_seqs.transpose(0,1)\n",
    "\n",
    "    return src_sents, tgt_sents, src_seqs, tgt_seqs, src_lens, tgt_lens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build vocabulary, dataset and data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper class to store dictionary of words & indicies\n",
    "\n",
    "PAD_token  = 0\n",
    "SOS_token = 1\n",
    "EOS_token = 2\n",
    "UNK_token = 3\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.trimmed = False\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"PAD\", 1: \"SOS\", 2: \"EOS\"}\n",
    "        self.n_words = 3 # Count default tokens\n",
    "\n",
    "    def index_words(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.index_word(word)\n",
    "\n",
    "    def index_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "    # Remove words below a certain count threshold\n",
    "    def trim(self, min_count):\n",
    "        if self.trimmed: return\n",
    "        self.trimmed = True\n",
    "        \n",
    "        keep_words = []\n",
    "        \n",
    "        for k, v in self.word2count.items():\n",
    "            if v >= min_count:\n",
    "                keep_words.append(k)\n",
    "\n",
    "        print('keep_words %s / %s = %.4f' % (\n",
    "            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n",
    "        ))\n",
    "\n",
    "        # Reinitialize dictionaries\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"PAD\", 1: \"SOS\", 2: \"EOS\"}\n",
    "        self.n_words = 3 # Count default tokens\n",
    "\n",
    "        for word in keep_words:\n",
    "            self.index_word(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, embedding=None, rnn_type='LSTM', hidden_size=128, num_layers=1, dropout=0.3, bidirectional=True):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.bidirectional = bidirectional\n",
    "        self.num_directions = 2 if bidirectional else 1\n",
    "        self.hidden_size = hidden_size // self.num_directions\n",
    "        \n",
    "        self.embedding = embedding\n",
    "        self.word_vec_size = self.embedding.embedding_dim\n",
    "        \n",
    "        self.rnn_type = rnn_type\n",
    "        self.rnn = getattr(nn, self.rnn_type)(\n",
    "                           input_size=self.word_vec_size,\n",
    "                           hidden_size=self.hidden_size,\n",
    "                           num_layers=self.num_layers,\n",
    "                           dropout=self.dropout, \n",
    "                           bidirectional=self.bidirectional)\n",
    "        \n",
    "    def forward(self, src_seqs, src_lens, hidden=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            - src_seqs: (max_src_len, batch_size)\n",
    "            - src_lens: (batch_size)\n",
    "        Returns:\n",
    "            - outputs: (max_src_len, batch_size, hidden_size * num_directions)\n",
    "            - hidden : (num_layers, batch_size, hidden_size * num_directions)\n",
    "        \"\"\"\n",
    "        \n",
    "        # (max_src_len, batch_size) => (max_src_len, batch_size, word_vec_size)\n",
    "        emb = self.embedding(src_seqs)\n",
    "\n",
    "        # packed_emb:\n",
    "        # - data: (sum(batch_sizes), word_vec_size)\n",
    "        # - batch_sizes: list of batch sizes\n",
    "        packed_emb = nn.utils.rnn.pack_padded_sequence(emb, src_lens)\n",
    "\n",
    "        # rnn(gru) returns:\n",
    "        # - packed_outputs: shape same as packed_emb\n",
    "        # - hidden: (num_layers * num_directions, batch_size, hidden_size) \n",
    "        packed_outputs, hidden = self.rnn(packed_emb, hidden)\n",
    "\n",
    "        # outputs: (max_src_len, batch_size, hidden_size * num_directions)\n",
    "        # output_lens == src_lensˇ\n",
    "        outputs, output_lens =  nn.utils.rnn.pad_packed_sequence(packed_outputs)\n",
    "        \n",
    "        if self.bidirectional:\n",
    "            # (num_layers * num_directions, batch_size, hidden_size) \n",
    "            # => (num_layers, batch_size, hidden_size * num_directions)\n",
    "            hidden = self._cat_directions(hidden)\n",
    "        \n",
    "        return outputs, hidden\n",
    "    \n",
    "    def _cat_directions(self, hidden):\n",
    "        \"\"\" If the encoder is bidirectional, do the following transformation.\n",
    "            Ref: https://github.com/IBM/pytorch-seq2seq/blob/master/seq2seq/models/DecoderRNN.py#L176\n",
    "            -----------------------------------------------------------\n",
    "            In: (num_layers * num_directions, batch_size, hidden_size)\n",
    "            (ex: num_layers=2, num_directions=2)\n",
    "\n",
    "            layer 1: forward__hidden(1)\n",
    "            layer 1: backward_hidden(1)\n",
    "            layer 2: forward__hidden(2)\n",
    "            layer 2: backward_hidden(2)\n",
    "\n",
    "            -----------------------------------------------------------\n",
    "            Out: (num_layers, batch_size, hidden_size * num_directions)\n",
    "\n",
    "            layer 1: forward__hidden(1) backward_hidden(1)\n",
    "            layer 2: forward__hidden(2) backward_hidden(2)\n",
    "        \"\"\"\n",
    "        def _cat(h):\n",
    "            return torch.cat([h[0:h.size(0):2], h[1:h.size(0):2]], 2)\n",
    "            \n",
    "        if isinstance(hidden, tuple):\n",
    "            # LSTM hidden contains a tuple (hidden state, cell state)\n",
    "            hidden = tuple([_cat(h) for h in hidden])\n",
    "        else:\n",
    "            # GRU hidden\n",
    "            hidden = _cat(hidden)\n",
    "            \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder with \"general attention\" mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, encoder, embedding=None, attention=True, bias=True, tie_embeddings=False, dropout=0.3):\n",
    "        \"\"\" General attention in `Effective Approaches to Attention-based Neural Machine Translation`\n",
    "            Ref: https://arxiv.org/abs/1508.04025\n",
    "            \n",
    "            Share input and output embeddings:\n",
    "            Ref:\n",
    "                - \"Using the Output Embedding to Improve Language Models\" (Press & Wolf 2016)\n",
    "                   https://arxiv.org/abs/1608.05859\n",
    "                - \"Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling\" (Inan et al. 2016)\n",
    "                   https://arxiv.org/abs/1611.01462\n",
    "        \"\"\"\n",
    "        super(LuongAttnDecoderRNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = encoder.hidden_size * encoder.num_directions\n",
    "        self.num_layers = encoder.num_layers\n",
    "        self.dropout = dropout\n",
    "        self.embedding = embedding\n",
    "        self.attention = attention\n",
    "        self.tie_embeddings = tie_embeddings\n",
    "        \n",
    "        self.vocab_size = self.embedding.num_embeddings\n",
    "        self.word_vec_size = self.embedding.embedding_dim\n",
    "        \n",
    "        self.rnn_type = encoder.rnn_type\n",
    "        self.rnn = getattr(nn, self.rnn_type)(\n",
    "                            input_size=self.word_vec_size,\n",
    "                            hidden_size=self.hidden_size,\n",
    "                            num_layers=self.num_layers,\n",
    "                            dropout=self.dropout)\n",
    "        \n",
    "        if self.attention:\n",
    "            self.W_a = nn.Linear(encoder.hidden_size * encoder.num_directions,\n",
    "                                 self.hidden_size, bias=bias)\n",
    "            self.W_c = nn.Linear(encoder.hidden_size * encoder.num_directions + self.hidden_size, \n",
    "                                 self.hidden_size, bias=bias)\n",
    "        \n",
    "        if self.tie_embeddings:\n",
    "            self.W_proj = nn.Linear(self.hidden_size, self.word_vec_size, bias=bias)\n",
    "            self.W_s = nn.Linear(self.word_vec_size, self.vocab_size, bias=bias)\n",
    "            self.W_s.weight = self.embedding.weight\n",
    "        else:\n",
    "            self.W_s = nn.Linear(self.hidden_size, self.vocab_size, bias=bias)\n",
    "        \n",
    "    def forward(self, input_seq, decoder_hidden, encoder_outputs, src_lens):\n",
    "        \"\"\" Args:\n",
    "            - input_seq      : (batch_size)\n",
    "            - decoder_hidden : (t=0) last encoder hidden state (num_layers * num_directions, batch_size, hidden_size) \n",
    "                               (t>0) previous decoder hidden state (num_layers, batch_size, hidden_size)\n",
    "            - encoder_outputs: (max_src_len, batch_size, hidden_size * num_directions)\n",
    "        \n",
    "            Returns:\n",
    "            - output           : (batch_size, vocab_size)\n",
    "            - decoder_hidden   : (num_layers, batch_size, hidden_size)\n",
    "            - attention_weights: (batch_size, max_src_len)\n",
    "        \"\"\"        \n",
    "        # (batch_size) => (seq_len=1, batch_size)\n",
    "        input_seq = input_seq.unsqueeze(0)\n",
    "        \n",
    "        # (seq_len=1, batch_size) => (seq_len=1, batch_size, word_vec_size) \n",
    "        emb = self.embedding(input_seq)\n",
    "        \n",
    "        # rnn returns:\n",
    "        # - decoder_output: (seq_len=1, batch_size, hidden_size)\n",
    "        # - decoder_hidden: (num_layers, batch_size, hidden_size)\n",
    "        decoder_output, decoder_hidden = self.rnn(emb, decoder_hidden)\n",
    "\n",
    "        # (seq_len=1, batch_size, hidden_size) => (batch_size, seq_len=1, hidden_size)\n",
    "        decoder_output = decoder_output.transpose(0,1)\n",
    "        \n",
    "        \"\"\" \n",
    "        ------------------------------------------------------------------------------------------\n",
    "        Notes of computing attention scores\n",
    "        ------------------------------------------------------------------------------------------\n",
    "        # For-loop version:\n",
    "\n",
    "        max_src_len = encoder_outputs.size(0)\n",
    "        batch_size = encoder_outputs.size(1)\n",
    "        attention_scores = Variable(torch.zeros(batch_size, max_src_len))\n",
    "\n",
    "        # For every batch, every time step of encoder's hidden state, calculate attention score.\n",
    "        for b in range(batch_size):\n",
    "            for t in range(max_src_len):\n",
    "                # Loung. eq(8) -- general form content-based attention:\n",
    "                attention_scores[b,t] = decoder_output[b].dot(attention.W_a(encoder_outputs[t,b]))\n",
    "\n",
    "        ------------------------------------------------------------------------------------------\n",
    "        # Vectorized version:\n",
    "\n",
    "        1. decoder_output: (batch_size, seq_len=1, hidden_size)\n",
    "        2. encoder_outputs: (max_src_len, batch_size, hidden_size * num_directions)\n",
    "        3. W_a(encoder_outputs): (max_src_len, batch_size, hidden_size)\n",
    "                        .transpose(0,1)  : (batch_size, max_src_len, hidden_size) \n",
    "                        .transpose(1,2)  : (batch_size, hidden_size, max_src_len)\n",
    "        4. attention_scores: \n",
    "                        (batch_size, seq_len=1, hidden_size) * (batch_size, hidden_size, max_src_len) \n",
    "                        => (batch_size, seq_len=1, max_src_len)\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.attention:\n",
    "            # attention_scores: (batch_size, seq_len=1, max_src_len)\n",
    "            attention_scores = torch.bmm(decoder_output, self.W_a(encoder_outputs).transpose(0,1).transpose(1,2))\n",
    "\n",
    "            # attention_mask: (batch_size, seq_len=1, max_src_len)\n",
    "            attention_mask = sequence_mask(src_lens).unsqueeze(1)\n",
    "\n",
    "            # Fills elements of tensor with `-float('inf')` where `mask` is 1.\n",
    "            attention_scores.data.masked_fill_(1 - attention_mask.data, -float('inf'))\n",
    "\n",
    "            # attention_weights: (batch_size, seq_len=1, max_src_len) => (batch_size, max_src_len) for `F.softmax` \n",
    "            # => (batch_size, seq_len=1, max_src_len)\n",
    "            try: # torch 0.3.x\n",
    "                attention_weights = F.softmax(attention_scores.squeeze(1), dim=1).unsqueeze(1)\n",
    "            except:\n",
    "                attention_weights = F.softmax(attention_scores.squeeze(1)).unsqueeze(1)\n",
    "\n",
    "            # context_vector:\n",
    "            # (batch_size, seq_len=1, max_src_len) * (batch_size, max_src_len, encoder_hidden_size * num_directions)\n",
    "            # => (batch_size, seq_len=1, encoder_hidden_size * num_directions)\n",
    "            context_vector = torch.bmm(attention_weights, encoder_outputs.transpose(0,1))\n",
    "\n",
    "            # concat_input: (batch_size, seq_len=1, encoder_hidden_size * num_directions + decoder_hidden_size)\n",
    "            concat_input = torch.cat([context_vector, decoder_output], -1)\n",
    "\n",
    "            # (batch_size, seq_len=1, encoder_hidden_size * num_directions + decoder_hidden_size) => (batch_size, seq_len=1, decoder_hidden_size)\n",
    "            concat_output = F.tanh(self.W_c(concat_input))\n",
    "            \n",
    "            # Prepare returns:\n",
    "            # (batch_size, seq_len=1, max_src_len) => (batch_size, max_src_len)\n",
    "            attention_weights = attention_weights.squeeze(1)\n",
    "        else:\n",
    "            attention_weights = None\n",
    "            concat_output = decoder_output\n",
    "        \n",
    "        # If input and output embeddings are tied,\n",
    "        # project `decoder_hidden_size` to `word_vec_size`.\n",
    "        if self.tie_embeddings:\n",
    "            output = self.W_s(self.W_proj(concat_output))\n",
    "        else:\n",
    "            # (batch_size, seq_len=1, decoder_hidden_size) => (batch_size, seq_len=1, vocab_size)\n",
    "            output = self.W_s(concat_output)    \n",
    "        \n",
    "        # Prepare returns:\n",
    "        # (batch_size, seq_len=1, vocab_size) => (batch_size, vocab_size)\n",
    "        output = output.squeeze(1)\n",
    "        \n",
    "        del src_lens\n",
    "        \n",
    "        return output, decoder_hidden, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_spacy_glove_embedding(spacy_nlp, vocab):\n",
    "    \n",
    "    vocab_size = len(vocab.token2id)\n",
    "    word_vec_size = spacy_nlp.vocab.vectors_length\n",
    "    embedding = np.zeros((vocab_size, word_vec_size))\n",
    "    unk_count = 0\n",
    "    \n",
    "    print('='*100)\n",
    "    print('Loading spacy glove embedding:')\n",
    "    print('- Vocabulary size: {}'.format(vocab_size))\n",
    "    print('- Word vector size: {}'.format(word_vec_size))\n",
    "    \n",
    "    for token, index in tqdm(vocab.token2id.items()):\n",
    "        if token == vocab.id2token[PAD]: \n",
    "            continue\n",
    "        elif token in [vocab.id2token[BOS], vocab.id2token[EOS], vocab.id2token[UNK]]: \n",
    "            vector = np.random.rand(word_vec_size,)\n",
    "        elif spacy_nlp.vocab[token].has_vector: \n",
    "            vector = spacy_nlp.vocab[token].vector\n",
    "        else:\n",
    "            vector = embedding[UNK] \n",
    "            unk_count += 1\n",
    "            \n",
    "        embedding[index] = vector\n",
    "        \n",
    "    print('- Unknown word count: {}'.format(unk_count))\n",
    "    print('='*100 + '\\n')\n",
    "    \n",
    "    return torch.from_numpy(embedding).float()\n",
    "\n",
    "def sequence_mask(sequence_length, max_len=None):\n",
    "    \"\"\"\n",
    "    Caution: Input and Return are VARIABLE.\n",
    "    \"\"\"\n",
    "    if max_len is None:\n",
    "        max_len = sequence_length.data.max()\n",
    "    batch_size = sequence_length.size(0)\n",
    "    seq_range = torch.arange(0, max_len).long()\n",
    "    seq_range_expand = seq_range.unsqueeze(0).expand(batch_size, max_len)\n",
    "    seq_range_expand = Variable(seq_range_expand)\n",
    "    if sequence_length.is_cuda:\n",
    "        seq_range_expand = seq_range_expand.cuda()\n",
    "    seq_length_expand = (sequence_length.unsqueeze(1)\n",
    "                         .expand_as(seq_range_expand))\n",
    "    mask = seq_range_expand < seq_length_expand\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def masked_cross_entropy(logits, target, length):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        logits: A Variable containing a FloatTensor of size\n",
    "            (batch, max_len, num_classes) which contains the\n",
    "            unnormalized probability for each class.\n",
    "        target: A Variable containing a LongTensor of size\n",
    "            (batch, max_len) which contains the index of the true\n",
    "            class for each corresponding step.\n",
    "        length: A Variable containing a LongTensor of size (batch,)\n",
    "            which contains the length of each data in a batch.\n",
    "    Returns:\n",
    "        loss: An average loss value masked by the length.\n",
    "        \n",
    "    The code is same as:\n",
    "    \n",
    "    weight = torch.ones(tgt_vocab_size)\n",
    "    weight[padding_idx] = 0\n",
    "    criterion = nn.CrossEntropyLoss(weight.cuda(), size_average)\n",
    "    loss = criterion(logits_flat, losses_flat)\n",
    "    \"\"\"\n",
    "    # logits_flat: (batch * max_len, num_classes)\n",
    "    logits_flat = logits.view(-1, logits.size(-1))\n",
    "    # log_probs_flat: (batch * max_len, num_classes)\n",
    "    log_probs_flat = F.log_softmax(logits_flat)\n",
    "    # target_flat: (batch * max_len, 1)\n",
    "    target_flat = target.view(-1, 1)\n",
    "    # losses_flat: (batch * max_len, 1)\n",
    "    losses_flat = -torch.gather(log_probs_flat, dim=1, index=target_flat)\n",
    "    # losses: (batch, max_len)\n",
    "    losses = losses_flat.view(*target.size())\n",
    "    # mask: (batch, max_len)\n",
    "    mask = sequence_mask(sequence_length=length, max_len=target.size(1))\n",
    "    # Note: mask need to bed casted to float!\n",
    "    losses = losses * mask.float()\n",
    "    loss = losses.sum() / mask.float().sum()\n",
    "    \n",
    "    # (batch_size * max_tgt_len,)\n",
    "    pred_flat = log_probs_flat.max(1)[1]\n",
    "    # (batch_size * max_tgt_len,) => (batch_size, max_tgt_len) => (max_tgt_len, batch_size)\n",
    "    pred_seqs = pred_flat.view(*target.size()).transpose(0,1).contiguous()\n",
    "    # (batch_size, max_len) => (batch_size * max_tgt_len,)\n",
    "    mask_flat = mask.view(-1)\n",
    "    \n",
    "    # `.float()` IS VERY IMPORTANT !!!\n",
    "    # https://discuss.pytorch.org/t/batch-size-and-validation-accuracy/4066/3\n",
    "    num_corrects = int(pred_flat.eq(target_flat.squeeze(1)).masked_select(mask_flat).float().data.sum())\n",
    "    num_words = length.data.sum()\n",
    "\n",
    "    return loss, pred_seqs, num_corrects, num_words\n",
    "\n",
    "def load_checkpoint(checkpoint_path):\n",
    "    # It's weird that if `map_location` is not given, it will be extremely slow.\n",
    "    return torch.load(checkpoint_path, map_location=lambda storage, loc: storage)\n",
    "\n",
    "def save_checkpoint(opts, experiment_name, encoder, decoder, encoder_optim, decoder_optim,\n",
    "                    total_accuracy, total_loss, global_step):\n",
    "    checkpoint = {\n",
    "        'opts': opts,\n",
    "        'global_step': global_step,\n",
    "        'encoder_state_dict': encoder.state_dict(),\n",
    "        'decoder_state_dict': decoder.state_dict(),\n",
    "        'encoder_optim_state_dict': encoder_optim.state_dict(),\n",
    "        'decoder_optim_state_dict': decoder_optim.state_dict()\n",
    "    }\n",
    "    \n",
    "    checkpoint_path = 'checkpoints/%s_acc_%.2f_loss_%.2f_step_%d.pt' % (experiment_name, total_accuracy, total_loss, global_step)\n",
    "    \n",
    "    directory, filename = os.path.split(os.path.abspath(checkpoint_path))\n",
    "\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    \n",
    "    return checkpoint_path\n",
    "\n",
    "def variable2numpy(var):\n",
    "    \"\"\" For tensorboard visualization \"\"\"\n",
    "    return var.data.cpu().numpy()\n",
    "\n",
    "def write_to_tensorboard(writer, global_step, total_loss, total_corrects, total_words, total_accuracy,\n",
    "                         encoder_grad_norm, decoder_grad_norm, clipped_encoder_grad_norm, clipped_decoder_grad_norm,\n",
    "                         encoder, decoder, gpu_memory_usage=None):\n",
    "    # scalars\n",
    "    if gpu_memory_usage is not None:\n",
    "        writer.add_scalar('curr_gpu_memory_usage', gpu_memory_usage['curr'], global_step)\n",
    "        writer.add_scalar('diff_gpu_memory_usage', gpu_memory_usage['diff'], global_step)\n",
    "        \n",
    "    writer.add_scalar('total_loss', total_loss, global_step)\n",
    "    writer.add_scalar('total_accuracy', total_accuracy, global_step)\n",
    "    writer.add_scalar('total_corrects', total_corrects, global_step)\n",
    "    writer.add_scalar('total_words', total_words, global_step)\n",
    "    writer.add_scalar('encoder_grad_norm', encoder_grad_norm, global_step)\n",
    "    writer.add_scalar('decoder_grad_norm', decoder_grad_norm, global_step)\n",
    "    writer.add_scalar('clipped_encoder_grad_norm', clipped_encoder_grad_norm, global_step)\n",
    "    writer.add_scalar('clipped_decoder_grad_norm', clipped_decoder_grad_norm, global_step)\n",
    "    \n",
    "    # histogram\n",
    "    for name, param in encoder.named_parameters():\n",
    "        name = name.replace('.', '/')\n",
    "        writer.add_histogram('encoder/{}'.format(name), variable2numpy(param), global_step, bins='doane')\n",
    "        if param.grad is not None:\n",
    "            writer.add_histogram('encoder/{}/grad'.format(name), variable2numpy(param.grad), global_step, bins='doane')\n",
    "\n",
    "    for name, param in decoder.named_parameters():\n",
    "        name = name.replace('.', '/')\n",
    "        writer.add_histogram('decoder/{}'.format(name), variable2numpy(param), global_step, bins='doane')\n",
    "        if param.grad is not None:\n",
    "            writer.add_histogram('decoder/{}/grad'.format(name), variable2numpy(param.grad), global_step, bins='doane')\n",
    "            \n",
    "def detach_hidden(hidden):\n",
    "    \"\"\" Wraps hidden states in new Variables, to detach them from their history. Prevent OOM.\n",
    "        After detach, the hidden's requires_grad=Fasle and grad_fn=None.\n",
    "    Issues:\n",
    "    - Memory leak problem in LSTM and RNN: https://github.com/pytorch/pytorch/issues/2198\n",
    "    - https://github.com/pytorch/examples/blob/master/word_language_model/main.py\n",
    "    - https://discuss.pytorch.org/t/help-clarifying-repackage-hidden-in-word-language-model/226\n",
    "    - https://discuss.pytorch.org/t/solved-why-we-need-to-detach-variable-which-contains-hidden-representation/1426\n",
    "    - \n",
    "    \"\"\"\n",
    "    if type(hidden) == Variable:\n",
    "        hidden.detach_() # same as creating a new variable.\n",
    "    else:\n",
    "        for h in hidden: h.detach_()\n",
    "\n",
    "def get_gpu_memory_usage(device_id):\n",
    "    \"\"\"Get the current gpu usage. \"\"\"\n",
    "    result = subprocess.check_output(\n",
    "        [\n",
    "            'nvidia-smi', '--query-gpu=memory.used',\n",
    "            '--format=csv,nounits,noheader'\n",
    "        ]).decode(\"utf-8\")\n",
    "    # Convert lines into a dictionary\n",
    "    gpu_memory = [int(x) for x in result.strip().split('\\n')]\n",
    "    gpu_memory_map = dict(zip(range(len(gpu_memory)), gpu_memory))\n",
    "    return gpu_memory_map[device_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_grad_norm(parameters, norm_type=2):\n",
    "    \"\"\" Ref: http://pytorch.org/docs/0.3.0/_modules/torch/nn/utils/clip_grad.html#clip_grad_norm\n",
    "    \"\"\"\n",
    "    parameters = list(filter(lambda p: p.grad is not None, parameters))\n",
    "    norm_type = float(norm_type)\n",
    "    if norm_type == float('inf'):\n",
    "        total_norm = max(p.grad.data.abs().max() for p in parameters)\n",
    "    else:\n",
    "        total_norm = 0\n",
    "        for p in parameters:\n",
    "            param_norm = p.grad.data.norm(norm_type)\n",
    "            total_norm += param_norm ** norm_type\n",
    "        total_norm = total_norm ** (1. / norm_type)\n",
    "    return total_norm\n",
    "\n",
    "def train(src_sents, tgt_sents, src_seqs, tgt_seqs, src_lens, tgt_lens,\n",
    "          encoder, decoder, encoder_optim, decoder_optim, opts):    \n",
    "    # -------------------------------------\n",
    "    # Prepare input and output placeholders\n",
    "    # -------------------------------------\n",
    "    # Last batch might not have the same size as we set to the `batch_size`\n",
    "    batch_size = src_seqs.size(1)\n",
    "    assert(batch_size == tgt_seqs.size(1))\n",
    "    \n",
    "    # Pack tensors to variables for neural network inputs (in order to autograd)\n",
    "    src_seqs = Variable(src_seqs)\n",
    "    tgt_seqs = Variable(tgt_seqs)\n",
    "    src_lens = Variable(torch.LongTensor(src_lens))\n",
    "    tgt_lens = Variable(torch.LongTensor(tgt_lens))\n",
    "\n",
    "    # Decoder's input\n",
    "    input_seq = Variable(torch.LongTensor([BOS] * batch_size))\n",
    "    \n",
    "    # Decoder's output sequence length = max target sequence length of current batch.\n",
    "    max_tgt_len = tgt_lens.data.max()\n",
    "    \n",
    "    # Store all decoder's outputs.\n",
    "    # **CRUTIAL** \n",
    "    # Don't set:\n",
    "    # >> decoder_outputs = Variable(torch.zeros(max_tgt_len, batch_size, decoder.vocab_size))\n",
    "    # Varying tensor size could cause GPU allocate a new memory causing OOM, \n",
    "    # so we intialize tensor with fixed size instead:\n",
    "    # `opts.max_seq_len` is a fixed number, unlike `max_tgt_len` always varys.\n",
    "    decoder_outputs = Variable(torch.zeros(opts.max_seq_len, batch_size, decoder.vocab_size))\n",
    "\n",
    "    # Move variables from CPU to GPU.\n",
    "    if USE_CUDA:\n",
    "        src_seqs = src_seqs.cuda()\n",
    "        tgt_seqs = tgt_seqs.cuda()\n",
    "        src_lens = src_lens.cuda()\n",
    "        tgt_lens = tgt_lens.cuda()\n",
    "        input_seq = input_seq.cuda()\n",
    "        decoder_outputs = decoder_outputs.cuda()\n",
    "        \n",
    "    # -------------------------------------\n",
    "    # Training mode (enable dropout)\n",
    "    # -------------------------------------\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    \n",
    "    # -------------------------------------\n",
    "    # Zero gradients, since optimizers will accumulate gradients for every backward.\n",
    "    # -------------------------------------\n",
    "    encoder_optim.zero_grad()\n",
    "    decoder_optim.zero_grad()\n",
    "        \n",
    "    # -------------------------------------\n",
    "    # Forward encoder\n",
    "    # -------------------------------------\n",
    "    encoder_outputs, encoder_hidden = encoder(src_seqs, src_lens.data.tolist())\n",
    "\n",
    "    # -------------------------------------\n",
    "    # Forward decoder\n",
    "    # -------------------------------------\n",
    "    # Initialize decoder's hidden state as encoder's last hidden state.\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    # Run through decoder one time step at a time.\n",
    "    for t in range(max_tgt_len):\n",
    "        \n",
    "        # decoder returns:\n",
    "        # - decoder_output   : (batch_size, vocab_size)\n",
    "        # - decoder_hidden   : (num_layers, batch_size, hidden_size)\n",
    "        # - attention_weights: (batch_size, max_src_len)\n",
    "        decoder_output, decoder_hidden, attention_weights = decoder(input_seq, decoder_hidden,\n",
    "                                                                    encoder_outputs, src_lens)\n",
    "\n",
    "        # Store decoder outputs.\n",
    "        decoder_outputs[t] = decoder_output\n",
    "        \n",
    "        # Next input is current target\n",
    "        input_seq = tgt_seqs[t]\n",
    "        \n",
    "        # Detach hidden state:\n",
    "        detach_hidden(decoder_hidden)\n",
    "        \n",
    "    # -------------------------------------\n",
    "    # Compute loss\n",
    "    # -------------------------------------\n",
    "    loss, pred_seqs, num_corrects, num_words = masked_cross_entropy(\n",
    "        decoder_outputs[:max_tgt_len].transpose(0,1).contiguous(), \n",
    "        tgt_seqs.transpose(0,1).contiguous(),\n",
    "        tgt_lens\n",
    "    )\n",
    "    \n",
    "    pred_seqs = pred_seqs[:max_tgt_len]\n",
    "    \n",
    "    # -------------------------------------\n",
    "    # Backward and optimize\n",
    "    # -------------------------------------\n",
    "    # Backward to get gradients w.r.t parameters in model.\n",
    "    loss.backward()\n",
    "    \n",
    "    # Clip gradients\n",
    "    encoder_grad_norm = nn.utils.clip_grad_norm(encoder.parameters(), opts.max_grad_norm)\n",
    "    decoder_grad_norm = nn.utils.clip_grad_norm(decoder.parameters(), opts.max_grad_norm)\n",
    "    clipped_encoder_grad_norm = compute_grad_norm(encoder.parameters())\n",
    "    clipped_decoder_grad_norm = compute_grad_norm(decoder.parameters())\n",
    "    \n",
    "    # Update parameters with optimizers\n",
    "    encoder_optim.step()\n",
    "    decoder_optim.step()\n",
    "        \n",
    "    return loss.data[0], pred_seqs, attention_weights, num_corrects, num_words,\\\n",
    "           encoder_grad_norm, decoder_grad_norm, clipped_encoder_grad_norm, clipped_decoder_grad_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[38;5;27mcheckpoints\u001b[0m/  masked_cross_entropy.py  \u001b[38;5;27mpyrouge\u001b[0m/          \u001b[38;5;27mtensorboard-logs\u001b[0m/\n",
      "\u001b[38;5;27mdata\u001b[0m/         \u001b[38;5;27mmodels\u001b[0m/                  \u001b[38;5;27mrouge\u001b[0m/            \u001b[38;5;27mtestout\u001b[0m/\n",
      "\u001b[38;5;27mfiles2rouge\u001b[0m/  \u001b[38;5;27mopennmt_jgfork\u001b[0m/          \u001b[38;5;27mrouge-baselines\u001b[0m/\n",
      "\u001b[38;5;9mglove.6B.zip\u001b[0m  \u001b[38;5;27mOpenNMT-py\u001b[0m/              \u001b[38;5;27mscripts\u001b[0m/\n",
      "\u001b[38;5;27mglove_dir\u001b[0m/    \u001b[38;5;27m__pycache__\u001b[0m/             seq2seq_01.ipynb\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Dataset preprocessing log:\n",
      "- Loading and tokenizing source sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 204061/204061 [00:21<00:00, 9613.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loading and tokenizing target sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 204061/204061 [00:03<00:00, 53752.34it/s]\n",
      "  2%|▏         | 3898/204061 [00:00<00:10, 19482.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Building source counter...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 204061/204061 [00:11<00:00, 18277.83it/s]\n",
      "  7%|▋         | 13681/204061 [00:00<00:01, 136784.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Building target counter...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 204061/204061 [00:01<00:00, 128144.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Building source vocabulary...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [00:00, 670852.50it/s]\n",
      "100%|██████████| 50004/50004 [00:00<00:00, 953075.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Building target vocabulary...\n",
      "====================================================================================================\n",
      "Dataset Info:\n",
      "- Number of source sentences: 204061\n",
      "- Number of target sentences: 204061\n",
      "- Source vocabulary size: 50004\n",
      "- Target vocabulary size: 50004\n",
      "- Shared vocabulary: True\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = NMTDataset(src_path='data/src-train.txt',\n",
    "                           tgt_path='data/tgt-train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Dataset preprocessing log:\n",
      "- Loading and tokenizing source sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25507/25507 [00:02<00:00, 11077.46it/s]\n",
      " 31%|███       | 7943/25507 [00:00<00:00, 79313.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loading and tokenizing target sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25507/25507 [00:00<00:00, 120998.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Dataset Info:\n",
      "- Number of source sentences: 25507\n",
      "- Number of target sentences: 25507\n",
      "- Source vocabulary size: 50004\n",
      "- Target vocabulary size: 50004\n",
      "- Shared vocabulary: True\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "valid_dataset = NMTDataset(src_path='data/src-val.txt',\n",
    "                           tgt_path='data/tgt-val.txt',\n",
    "                           src_vocab=train_dataset.src_vocab,\n",
    "                           tgt_vocab=train_dataset.tgt_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_iter = DataLoader(dataset=train_dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True,\n",
    "                        num_workers=4,\n",
    "                        collate_fn=collate_fn)\n",
    "\n",
    "valid_iter = DataLoader(dataset=valid_dataset,\n",
    "                        batch_size=batch_size, \n",
    "                        shuffle=False,\n",
    "                        num_workers=4,\n",
    "                        collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If enabled, load checkpoint.\n",
    "LOAD_CHECKPOINT = False\n",
    "\n",
    "if LOAD_CHECKPOINT:\n",
    "    # Modify this path.\n",
    "    checkpoint_path = './checkpoints/seq2seq_2018-02-07 20:30:47_acc_88.15_loss_12.85_step_135000.pt'\n",
    "    checkpoint = load_checkpoint(checkpoint_path)\n",
    "    opts = checkpoint['opts']    \n",
    "else:\n",
    "    opts = AttrDict()\n",
    "\n",
    "    # Configure models\n",
    "    opts.word_vec_size = 300\n",
    "    opts.rnn_type = 'LSTM'\n",
    "    opts.hidden_size = 512\n",
    "    opts.num_layers = 2\n",
    "    opts.dropout = 0.3\n",
    "    opts.bidirectional = True\n",
    "    opts.attention = True\n",
    "    opts.share_embeddings = True\n",
    "    opts.pretrained_embeddings = True\n",
    "    opts.fixed_embeddings = True\n",
    "    opts.tie_embeddings = True # Tie decoder's input and output embeddings\n",
    "\n",
    "    # Configure optimization\n",
    "    opts.max_grad_norm = 2\n",
    "    opts.learning_rate = 0.001\n",
    "    opts.weight_decay = 1e-5 # L2 weight regularization\n",
    "    \n",
    "    # Configure training\n",
    "    opts.max_seq_len = 500 # max sequence length to prevent OOM.\n",
    "    opts.num_epochs = 16\n",
    "    opts.print_every_step = 100\n",
    "    opts.save_every_step = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Options log:\n",
      "- Load from checkpoint: False\n",
      "- tie_embeddings: True\n",
      "- max_seq_len: 500\n",
      "- print_every_step: 100\n",
      "- hidden_size: 512\n",
      "- attention: True\n",
      "- num_epochs: 16\n",
      "- dropout: 0.3\n",
      "- fixed_embeddings: True\n",
      "- share_embeddings: True\n",
      "- weight_decay: 1e-05\n",
      "- rnn_type: LSTM\n",
      "- num_layers: 2\n",
      "- learning_rate: 0.001\n",
      "- word_vec_size: 300\n",
      "- max_grad_norm: 2\n",
      "- pretrained_embeddings: True\n",
      "- save_every_step: 5000\n",
      "- bidirectional: True\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('='*100)\n",
    "print('Options log:')\n",
    "print('- Load from checkpoint: {}'.format(LOAD_CHECKPOINT))\n",
    "if LOAD_CHECKPOINT: print('- Global step: {}'.format(checkpoint['global_step']))\n",
    "for k,v in opts.items(): print('- {}: {}'.format(k, v))\n",
    "print('='*100 + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize embeddings and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4128/50004 [00:00<00:01, 41261.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Loading spacy glove embedding:\n",
      "- Vocabulary size: 50004\n",
      "- Word vector size: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50004/50004 [00:00<00:00, 71548.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Unknown word count: 4504\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize vocabulary size.\n",
    "src_vocab_size = len(train_dataset.src_vocab.token2id)\n",
    "tgt_vocab_size = len(train_dataset.tgt_vocab.token2id)\n",
    "\n",
    "# Initialize embeddings.\n",
    "# We can actually put all modules in one module like `NMTModel`)\n",
    "# See: https://github.com/spro/practical-pytorch/issues/34\n",
    "word_vec_size = opts.word_vec_size if not opts.pretrained_embeddings else nlp.vocab.vectors_length\n",
    "src_embedding = nn.Embedding(src_vocab_size, opts.word_vec_size, padding_idx=PAD)\n",
    "tgt_embedding = nn.Embedding(tgt_vocab_size, opts.word_vec_size, padding_idx=PAD)\n",
    "\n",
    "if opts.share_embeddings:\n",
    "    assert(src_vocab_size == tgt_vocab_size)\n",
    "    tgt_embedding.weight = src_embedding.weight\n",
    "\n",
    "# Initialize models.\n",
    "encoder = EncoderRNN(embedding=src_embedding,\n",
    "                     rnn_type=opts.rnn_type,\n",
    "                     hidden_size=opts.hidden_size,\n",
    "                     num_layers=opts.num_layers,\n",
    "                     dropout=opts.dropout,\n",
    "                     bidirectional=opts.bidirectional)\n",
    "\n",
    "decoder = LuongAttnDecoderRNN(encoder, embedding=tgt_embedding,\n",
    "                              attention=opts.attention,\n",
    "                              tie_embeddings=opts.tie_embeddings,\n",
    "                              dropout=opts.dropout)\n",
    "\n",
    "if opts.pretrained_embeddings:\n",
    "    glove_embeddings = load_spacy_glove_embedding(nlp, train_dataset.src_vocab)\n",
    "    encoder.embedding.weight.data.copy_(glove_embeddings)\n",
    "    decoder.embedding.weight.data.copy_(glove_embeddings)\n",
    "    if opts.fixed_embeddings:\n",
    "        encoder.embedding.weight.requires_grad = False\n",
    "        decoder.embedding.weight.requires_grad = False\n",
    "        \n",
    "if LOAD_CHECKPOINT:\n",
    "    encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "    decoder.load_state_dict(checkpoint['decoder_state_dict'])\n",
    "    \n",
    "# Move models to GPU (need time for initial run)\n",
    "if USE_CUDA:\n",
    "    encoder.cuda()\n",
    "    decoder.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINE_TUNE = True\n",
    "if FINE_TUNE:\n",
    "    encoder.embedding.weight.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Model log:\n",
      "\n",
      "EncoderRNN(\n",
      "  (embedding): Embedding(50004, 300, padding_idx=0)\n",
      "  (rnn): LSTM(300, 256, num_layers=2, dropout=0.3, bidirectional=True)\n",
      ")\n",
      "LuongAttnDecoderRNN(\n",
      "  (embedding): Embedding(50004, 300, padding_idx=0)\n",
      "  (rnn): LSTM(300, 512, num_layers=2, dropout=0.3)\n",
      "  (W_a): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (W_c): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (W_proj): Linear(in_features=512, out_features=300, bias=True)\n",
      "  (W_s): Linear(in_features=300, out_features=50004, bias=True)\n",
      ")\n",
      "- Encoder input embedding requires_grad=True\n",
      "- Decoder input embedding requires_grad=True\n",
      "- Decoder output embedding requires_grad=True\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('='*100)\n",
    "print('Model log:\\n')\n",
    "print(encoder)\n",
    "print(decoder)\n",
    "print('- Encoder input embedding requires_grad={}'.format(encoder.embedding.weight.requires_grad))\n",
    "print('- Decoder input embedding requires_grad={}'.format(decoder.embedding.weight.requires_grad))\n",
    "print('- Decoder output embedding requires_grad={}'.format(decoder.W_s.weight.requires_grad))\n",
    "print('='*100 + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize optimizers (we can experiment different learning rates)\n",
    "encoder_optim = optim.Adam([p for p in encoder.parameters() if p.requires_grad], lr=opts.learning_rate, weight_decay=opts.weight_decay)\n",
    "decoder_optim = optim.Adam([p for p in decoder.parameters() if p.requires_grad], lr=opts.learning_rate, weight_decay=opts.weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Open port 6006 and see tensorboard.\n",
    "    Ref:  https://medium.com/@dexterhuang/%E7%B5%A6-pytorch-%E7%94%A8%E7%9A%84-tensorboard-bb341ce3f837\n",
    "\"\"\"\n",
    "from datetime import datetime\n",
    "from tensorboardX import SummaryWriter\n",
    "# --------------------------\n",
    "# Configure tensorboard\n",
    "# --------------------------\n",
    "model_name = 'seq2seq_luong'\n",
    "datetime = ('%s' % datetime.now()).split('.')[0]\n",
    "experiment_name = '{}_{}'.format(model_name, datetime)\n",
    "tensorboard_log_dir = './tensorboard-logs/{}/'.format(experiment_name)\n",
    "writer = SummaryWriter(tensorboard_log_dir)\n",
    "\n",
    "# --------------------------\n",
    "# Configure training\n",
    "# --------------------------\n",
    "num_epochs = opts.num_epochs\n",
    "print_every_step = opts.print_every_step\n",
    "save_every_step = opts.save_every_step\n",
    "# For saving checkpoint and tensorboard\n",
    "global_step = 0 if not LOAD_CHECKPOINT else checkpoint['global_step']\n",
    "\n",
    "# --------------------------\n",
    "# Start training\n",
    "# --------------------------\n",
    "total_loss = 0\n",
    "total_corrects = 0\n",
    "total_words = 0\n",
    "prev_gpu_memory_usage = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "99it [03:04,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 100\n",
      "- Total loss: 709.7167358398438\n",
      "- Total corrects: 7727\n",
      "- Total words: 61631\n",
      "- Total accuracy: 12.537521701741007\n",
      "- Current GPU memory usage: 9984\n",
      "- Diff GPU memory usage: 9984\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [03:15,  1.96s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "199it [06:22,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 200\n",
      "- Total loss: 620.8501586914062\n",
      "- Total corrects: 10935\n",
      "- Total words: 61965\n",
      "- Total accuracy: 17.647058823529413\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 21\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [06:34,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "299it [09:39,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 300\n",
      "- Total loss: 598.5364990234375\n",
      "- Total corrects: 11471\n",
      "- Total words: 61232\n",
      "- Total accuracy: 18.733668669976485\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300it [09:50,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "399it [12:57,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 400\n",
      "- Total loss: 580.0555419921875\n",
      "- Total corrects: 12379\n",
      "- Total words: 61323\n",
      "- Total accuracy: 20.186553169283954\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400it [13:08,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "499it [16:11,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 500\n",
      "- Total loss: 568.1024780273438\n",
      "- Total corrects: 12916\n",
      "- Total words: 61526\n",
      "- Total accuracy: 20.992751032083998\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [16:23,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "599it [19:28,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 600\n",
      "- Total loss: 564.6480712890625\n",
      "- Total corrects: 12974\n",
      "- Total words: 61451\n",
      "- Total accuracy: 21.112756505182993\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "600it [19:40,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "699it [22:47,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 700\n",
      "- Total loss: 549.9303588867188\n",
      "- Total corrects: 13602\n",
      "- Total words: 61677\n",
      "- Total accuracy: 22.053601828882726\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "700it [22:58,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "799it [26:03,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 800\n",
      "- Total loss: 546.0242919921875\n",
      "- Total corrects: 13805\n",
      "- Total words: 62026\n",
      "- Total accuracy: 22.256795537355302\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "800it [26:14,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "899it [29:18,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 900\n",
      "- Total loss: 540.3023681640625\n",
      "- Total corrects: 14139\n",
      "- Total words: 61803\n",
      "- Total accuracy: 22.877530216979757\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "900it [29:30,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "999it [32:35,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 1000\n",
      "- Total loss: 530.0436401367188\n",
      "- Total corrects: 14520\n",
      "- Total words: 62004\n",
      "- Total accuracy: 23.417844010063867\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [32:46,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "1099it [35:49,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 1100\n",
      "- Total loss: 524.7367553710938\n",
      "- Total corrects: 15033\n",
      "- Total words: 61433\n",
      "- Total accuracy: 24.47056142464148\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1100it [36:01,  1.96s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "1199it [39:09,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 1200\n",
      "- Total loss: 519.1316528320312\n",
      "- Total corrects: 15247\n",
      "- Total words: 61937\n",
      "- Total accuracy: 24.616949480924166\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1200it [39:22,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "1299it [42:28,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 1300\n",
      "- Total loss: 517.5873413085938\n",
      "- Total corrects: 15267\n",
      "- Total words: 61491\n",
      "- Total accuracy: 24.828023613211688\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1300it [42:39,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "1399it [45:43,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 1400\n",
      "- Total loss: 515.3377075195312\n",
      "- Total corrects: 15402\n",
      "- Total words: 61418\n",
      "- Total accuracy: 25.0773388908789\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1400it [45:54,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "1499it [48:57,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 1500\n",
      "- Total loss: 506.2568359375\n",
      "- Total corrects: 15958\n",
      "- Total words: 61838\n",
      "- Total accuracy: 25.806138620265855\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1500it [49:08,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "1599it [52:12,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 1600\n",
      "- Total loss: 504.4171447753906\n",
      "- Total corrects: 15878\n",
      "- Total words: 61346\n",
      "- Total accuracy: 25.882698138427934\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1600it [52:24,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "1699it [55:31,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 1700\n",
      "- Total loss: 499.32745361328125\n",
      "- Total corrects: 16434\n",
      "- Total words: 61896\n",
      "- Total accuracy: 26.550988755331524\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1700it [55:42,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "1799it [58:46,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 1800\n",
      "- Total loss: 491.6605224609375\n",
      "- Total corrects: 16849\n",
      "- Total words: 61151\n",
      "- Total accuracy: 27.553106245196318\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1800it [58:59,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "1899it [1:02:02,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 1900\n",
      "- Total loss: 489.5761413574219\n",
      "- Total corrects: 17007\n",
      "- Total words: 61682\n",
      "- Total accuracy: 27.572063162673068\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1900it [1:02:15,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "1999it [1:05:23,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 2000\n",
      "- Total loss: 482.0840148925781\n",
      "- Total corrects: 17693\n",
      "- Total words: 62165\n",
      "- Total accuracy: 28.46135285128288\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [1:05:34,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "2099it [1:08:41,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 2100\n",
      "- Total loss: 478.56329345703125\n",
      "- Total corrects: 18108\n",
      "- Total words: 61975\n",
      "- Total accuracy: 29.218233158531664\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2100it [1:08:53,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "2199it [1:11:59,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 2200\n",
      "- Total loss: 472.9972229003906\n",
      "- Total corrects: 18530\n",
      "- Total words: 61631\n",
      "- Total accuracy: 30.06603819506417\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2200it [1:12:11,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "2299it [1:15:18,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 2300\n",
      "- Total loss: 468.94366455078125\n",
      "- Total corrects: 19049\n",
      "- Total words: 61819\n",
      "- Total accuracy: 30.814150989178085\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2300it [1:15:30,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "2399it [1:18:36,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 2400\n",
      "- Total loss: 460.8404541015625\n",
      "- Total corrects: 19692\n",
      "- Total words: 62209\n",
      "- Total accuracy: 31.654583741902297\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2400it [1:18:48,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "2499it [1:21:57,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 2500\n",
      "- Total loss: 459.0385437011719\n",
      "- Total corrects: 19833\n",
      "- Total words: 61667\n",
      "- Total accuracy: 32.16144777595797\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2500it [1:22:08,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "2599it [1:25:15,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 2600\n",
      "- Total loss: 449.64276123046875\n",
      "- Total corrects: 20423\n",
      "- Total words: 61593\n",
      "- Total accuracy: 33.15798873248583\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2600it [1:25:26,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "2699it [1:28:32,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 2700\n",
      "- Total loss: 448.1823425292969\n",
      "- Total corrects: 20737\n",
      "- Total words: 61896\n",
      "- Total accuracy: 33.502972728447716\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2700it [1:28:43,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "2799it [1:31:50,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 2800\n",
      "- Total loss: 444.4446105957031\n",
      "- Total corrects: 21023\n",
      "- Total words: 61407\n",
      "- Total accuracy: 34.235510609539624\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2800it [1:32:02,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "2899it [1:35:10,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 2900\n",
      "- Total loss: 444.6877136230469\n",
      "- Total corrects: 21250\n",
      "- Total words: 61939\n",
      "- Total accuracy: 34.30794814252732\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2900it [1:35:22,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "2999it [1:38:28,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 3000\n",
      "- Total loss: 442.7160339355469\n",
      "- Total corrects: 21217\n",
      "- Total words: 61805\n",
      "- Total accuracy: 34.32893778820484\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [1:38:39,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "3099it [1:41:43,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 3100\n",
      "- Total loss: 436.8300476074219\n",
      "- Total corrects: 21642\n",
      "- Total words: 61770\n",
      "- Total accuracy: 35.036425449247204\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3100it [1:41:55,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "3199it [1:45:01,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 3200\n",
      "- Total loss: 436.7801208496094\n",
      "- Total corrects: 21508\n",
      "- Total words: 61723\n",
      "- Total accuracy: 34.84600554088427\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3200it [1:45:13,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "3299it [1:48:21,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 3300\n",
      "- Total loss: 438.06451416015625\n",
      "- Total corrects: 21610\n",
      "- Total words: 62118\n",
      "- Total accuracy: 34.78862809491613\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3300it [1:48:33,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "3399it [1:51:40,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 3400\n",
      "- Total loss: 433.6253356933594\n",
      "- Total corrects: 21873\n",
      "- Total words: 61768\n",
      "- Total accuracy: 35.41153995596426\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3400it [1:51:51,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "3499it [1:54:57,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 3500\n",
      "- Total loss: 432.63201904296875\n",
      "- Total corrects: 21917\n",
      "- Total words: 61552\n",
      "- Total accuracy: 35.6072913958929\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3500it [1:55:09,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "3599it [1:58:14,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 3600\n",
      "- Total loss: 431.7691345214844\n",
      "- Total corrects: 21969\n",
      "- Total words: 61605\n",
      "- Total accuracy: 35.661066471877284\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3600it [1:58:25,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "3699it [2:01:30,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 3700\n",
      "- Total loss: 435.89959716796875\n",
      "- Total corrects: 21569\n",
      "- Total words: 61353\n",
      "- Total accuracy: 35.15557511450133\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3700it [2:01:42,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "3799it [2:04:48,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 3800\n",
      "- Total loss: 424.2230224609375\n",
      "- Total corrects: 22369\n",
      "- Total words: 61266\n",
      "- Total accuracy: 36.51127868638396\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3800it [2:04:59,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "3899it [2:08:06,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 3900\n",
      "- Total loss: 426.9859619140625\n",
      "- Total corrects: 22328\n",
      "- Total words: 61737\n",
      "- Total accuracy: 36.16631841521291\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3900it [2:08:17,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "3999it [2:11:24,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 4000\n",
      "- Total loss: 419.8102722167969\n",
      "- Total corrects: 22897\n",
      "- Total words: 62242\n",
      "- Total accuracy: 36.787056971177016\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4000it [2:11:36,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "4099it [2:14:41,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 4100\n",
      "- Total loss: 418.5194396972656\n",
      "- Total corrects: 22941\n",
      "- Total words: 61618\n",
      "- Total accuracy: 37.23100392742381\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4100it [2:14:53,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "4199it [2:17:58,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 4200\n",
      "- Total loss: 423.7531433105469\n",
      "- Total corrects: 22388\n",
      "- Total words: 61613\n",
      "- Total accuracy: 36.33648742960089\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4200it [2:18:10,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "4299it [2:21:13,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 4300\n",
      "- Total loss: 421.50042724609375\n",
      "- Total corrects: 22640\n",
      "- Total words: 61914\n",
      "- Total accuracy: 36.5668507930355\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4300it [2:21:24,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "4399it [2:24:30,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 4400\n",
      "- Total loss: 424.8782958984375\n",
      "- Total corrects: 22152\n",
      "- Total words: 61123\n",
      "- Total accuracy: 36.241676619275886\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4400it [2:24:41,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "4499it [2:27:51,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 4500\n",
      "- Total loss: 420.96728515625\n",
      "- Total corrects: 22691\n",
      "- Total words: 61892\n",
      "- Total accuracy: 36.66225037161507\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4500it [2:28:02,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "4599it [2:31:10,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 4600\n",
      "- Total loss: 419.7371520996094\n",
      "- Total corrects: 22934\n",
      "- Total words: 61974\n",
      "- Total accuracy: 37.00584115919579\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4600it [2:31:21,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "4699it [2:34:27,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 4700\n",
      "- Total loss: 414.6387634277344\n",
      "- Total corrects: 23160\n",
      "- Total words: 62036\n",
      "- Total accuracy: 37.333161390160555\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4700it [2:34:39,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "4799it [2:37:44,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 4800\n",
      "- Total loss: 415.70806884765625\n",
      "- Total corrects: 22812\n",
      "- Total words: 61207\n",
      "- Total accuracy: 37.2702468671884\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4800it [2:37:56,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "4899it [2:41:01,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 4900\n",
      "- Total loss: 416.75079345703125\n",
      "- Total corrects: 22974\n",
      "- Total words: 61438\n",
      "- Total accuracy: 37.39379537094307\n",
      "- Current GPU memory usage: 10005\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4900it [2:41:12,  1.97s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "4999it [2:44:17,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Save checkpoint to \"checkpoints/seq2seq_luong_2018-07-23 17:34:35_acc_37.16_loss_417.09_step_5000.pt\".\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 5000\n",
      "- Total loss: 417.09423828125\n",
      "- Total corrects: 22907\n",
      "- Total words: 61641\n",
      "- Total accuracy: 37.16195389432359\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 25\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5000it [2:44:55,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "5099it [2:47:58,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 5100\n",
      "- Total loss: 414.6805419921875\n",
      "- Total corrects: 23096\n",
      "- Total words: 61664\n",
      "- Total accuracy: 37.454592631032696\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5100it [2:48:09,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "5199it [2:51:15,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 5200\n",
      "- Total loss: 417.47332763671875\n",
      "- Total corrects: 22960\n",
      "- Total words: 61871\n",
      "- Total accuracy: 37.10946970309192\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5200it [2:51:27,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "5299it [2:54:33,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 5300\n",
      "- Total loss: 413.1145935058594\n",
      "- Total corrects: 23108\n",
      "- Total words: 61596\n",
      "- Total accuracy: 37.51542307942074\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5300it [2:54:45,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "5399it [2:57:47,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 5400\n",
      "- Total loss: 415.30755615234375\n",
      "- Total corrects: 22775\n",
      "- Total words: 61219\n",
      "- Total accuracy: 37.2025024910567\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5400it [2:57:59,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "5499it [3:01:03,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 5500\n",
      "- Total loss: 411.56622314453125\n",
      "- Total corrects: 23413\n",
      "- Total words: 61773\n",
      "- Total accuracy: 37.90167225163097\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5500it [3:01:14,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "5599it [3:04:18,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 5600\n",
      "- Total loss: 415.5508728027344\n",
      "- Total corrects: 22962\n",
      "- Total words: 61974\n",
      "- Total accuracy: 37.051021396069316\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5600it [3:04:30,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "5699it [3:07:36,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 5700\n",
      "- Total loss: 416.23046875\n",
      "- Total corrects: 22922\n",
      "- Total words: 61667\n",
      "- Total accuracy: 37.170609888595195\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5700it [3:07:48,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "5799it [3:10:53,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 5800\n",
      "- Total loss: 410.9043884277344\n",
      "- Total corrects: 23483\n",
      "- Total words: 61608\n",
      "- Total accuracy: 38.11680301259577\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5800it [3:11:04,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "5899it [3:14:11,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 5900\n",
      "- Total loss: 411.0638427734375\n",
      "- Total corrects: 23595\n",
      "- Total words: 62150\n",
      "- Total accuracy: 37.9646017699115\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5900it [3:14:22,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "5999it [3:17:28,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 6000\n",
      "- Total loss: 408.42864990234375\n",
      "- Total corrects: 23697\n",
      "- Total words: 62050\n",
      "- Total accuracy: 38.19016921837228\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6000it [3:17:40,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "6099it [3:20:45,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 6100\n",
      "- Total loss: 408.5479736328125\n",
      "- Total corrects: 23719\n",
      "- Total words: 61831\n",
      "- Total accuracy: 38.3610163186751\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6100it [3:20:56,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "6199it [3:24:02,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 6200\n",
      "- Total loss: 403.0873107910156\n",
      "- Total corrects: 23713\n",
      "- Total words: 61184\n",
      "- Total accuracy: 38.75686453974895\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6200it [3:24:13,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "6299it [3:27:25,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 6300\n",
      "- Total loss: 411.29022216796875\n",
      "- Total corrects: 23217\n",
      "- Total words: 61632\n",
      "- Total accuracy: 37.670366043613704\n",
      "- Current GPU memory usage: 10603\n",
      "- Diff GPU memory usage: 573\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6300it [3:27:38,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "6399it [3:30:43,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 6400\n",
      "- Total loss: 408.5035400390625\n",
      "- Total corrects: 23355\n",
      "- Total words: 61688\n",
      "- Total accuracy: 37.85987550252886\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: -573\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6400it [3:30:55,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "6499it [3:33:58,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 6500\n",
      "- Total loss: 407.1068420410156\n",
      "- Total corrects: 23643\n",
      "- Total words: 61557\n",
      "- Total accuracy: 38.4083044982699\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6500it [3:34:10,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "6599it [3:37:28,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 6600\n",
      "- Total loss: 408.48736572265625\n",
      "- Total corrects: 23266\n",
      "- Total words: 61599\n",
      "- Total accuracy: 37.77009367035179\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6600it [3:37:40,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "6699it [3:40:45,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 6700\n",
      "- Total loss: 399.9681701660156\n",
      "- Total corrects: 24062\n",
      "- Total words: 61284\n",
      "- Total accuracy: 39.2631029306181\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6700it [3:40:56,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "6799it [3:44:11,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 6800\n",
      "- Total loss: 403.21331787109375\n",
      "- Total corrects: 23832\n",
      "- Total words: 61927\n",
      "- Total accuracy: 38.48402150919632\n",
      "- Current GPU memory usage: 10585\n",
      "- Diff GPU memory usage: 555\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6800it [3:44:23,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "6899it [3:47:27,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 6900\n",
      "- Total loss: 404.0152893066406\n",
      "- Total corrects: 23770\n",
      "- Total words: 61607\n",
      "- Total accuracy: 38.58327787426754\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: -555\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6900it [3:47:39,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "6999it [3:50:44,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 7000\n",
      "- Total loss: 402.35858154296875\n",
      "- Total corrects: 23801\n",
      "- Total words: 61640\n",
      "- Total accuracy: 38.61291369240753\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7000it [3:50:56,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "7099it [3:54:02,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 7100\n",
      "- Total loss: 406.0552978515625\n",
      "- Total corrects: 23714\n",
      "- Total words: 61896\n",
      "- Total accuracy: 38.31265348326225\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7100it [3:54:14,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "7199it [3:57:20,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 7200\n",
      "- Total loss: 405.9815673828125\n",
      "- Total corrects: 23673\n",
      "- Total words: 61685\n",
      "- Total accuracy: 38.37723919915701\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7200it [3:57:32,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "7299it [4:00:41,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 7300\n",
      "- Total loss: 401.1165771484375\n",
      "- Total corrects: 23918\n",
      "- Total words: 61993\n",
      "- Total accuracy: 38.58177536173439\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7300it [4:00:53,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "7399it [4:04:03,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 7400\n",
      "- Total loss: 394.8401794433594\n",
      "- Total corrects: 24480\n",
      "- Total words: 61811\n",
      "- Total accuracy: 39.6046011227775\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7400it [4:04:15,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "7499it [4:07:22,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 7500\n",
      "- Total loss: 401.29962158203125\n",
      "- Total corrects: 23823\n",
      "- Total words: 61820\n",
      "- Total accuracy: 38.53607246845681\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7500it [4:07:34,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "7599it [4:10:54,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 7600\n",
      "- Total loss: 399.07861328125\n",
      "- Total corrects: 23950\n",
      "- Total words: 61844\n",
      "- Total accuracy: 38.726473061250886\n",
      "- Current GPU memory usage: 10604\n",
      "- Diff GPU memory usage: 574\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7600it [4:11:06,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "7699it [4:14:19,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 7700\n",
      "- Total loss: 395.95465087890625\n",
      "- Total corrects: 24421\n",
      "- Total words: 61940\n",
      "- Total accuracy: 39.426864707781725\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: -574\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7700it [4:14:31,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "7799it [4:17:40,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 7800\n",
      "- Total loss: 401.6875\n",
      "- Total corrects: 23937\n",
      "- Total words: 61938\n",
      "- Total accuracy: 38.64671122735639\n",
      "- Current GPU memory usage: 10585\n",
      "- Diff GPU memory usage: 555\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7800it [4:17:53,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "7899it [4:21:08,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 7900\n",
      "- Total loss: 399.23138427734375\n",
      "- Total corrects: 23895\n",
      "- Total words: 61481\n",
      "- Total accuracy: 38.86566581545518\n",
      "- Current GPU memory usage: 10604\n",
      "- Diff GPU memory usage: 19\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7900it [4:21:21,  1.99s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "7999it [4:24:39,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 8000\n",
      "- Total loss: 405.0520935058594\n",
      "- Total corrects: 23536\n",
      "- Total words: 61566\n",
      "- Total accuracy: 38.22889257057467\n",
      "- Current GPU memory usage: 10586\n",
      "- Diff GPU memory usage: -18\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8000it [4:24:51,  1.99s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "8099it [4:28:11,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 8100\n",
      "- Total loss: 399.1046142578125\n",
      "- Total corrects: 23947\n",
      "- Total words: 61324\n",
      "- Total accuracy: 39.04996412497554\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: -556\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8100it [4:28:23,  1.99s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "8199it [4:31:35,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 8200\n",
      "- Total loss: 393.3941650390625\n",
      "- Total corrects: 24542\n",
      "- Total words: 61723\n",
      "- Total accuracy: 39.76151515642467\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8200it [4:31:47,  1.99s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "8299it [4:34:53,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 8300\n",
      "- Total loss: 398.8774719238281\n",
      "- Total corrects: 23967\n",
      "- Total words: 61686\n",
      "- Total accuracy: 38.85322439451415\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8300it [4:35:05,  1.99s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "8399it [4:38:19,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 8400\n",
      "- Total loss: 400.2917785644531\n",
      "- Total corrects: 23843\n",
      "- Total words: 61811\n",
      "- Total accuracy: 38.57404021937843\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8400it [4:38:31,  1.99s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "8499it [4:41:43,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 8500\n",
      "- Total loss: 395.68109130859375\n",
      "- Total corrects: 24369\n",
      "- Total words: 61922\n",
      "- Total accuracy: 39.3543490197345\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8500it [4:41:55,  1.99s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "8599it [4:45:02,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 8600\n",
      "- Total loss: 399.5399475097656\n",
      "- Total corrects: 24021\n",
      "- Total words: 62093\n",
      "- Total accuracy: 38.68552010693637\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8600it [4:45:14,  1.99s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "8699it [4:48:25,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 8700\n",
      "- Total loss: 397.192138671875\n",
      "- Total corrects: 23858\n",
      "- Total words: 61323\n",
      "- Total accuracy: 38.9054677690263\n",
      "- Current GPU memory usage: 10319\n",
      "- Diff GPU memory usage: 289\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8700it [4:48:37,  1.99s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "8799it [4:51:57,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 8800\n",
      "- Total loss: 398.808349609375\n",
      "- Total corrects: 23970\n",
      "- Total words: 62022\n",
      "- Total accuracy: 38.6475766663442\n",
      "- Current GPU memory usage: 11147\n",
      "- Diff GPU memory usage: 828\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8800it [4:52:09,  1.99s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "8899it [4:55:32,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 8900\n",
      "- Total loss: 396.39361572265625\n",
      "- Total corrects: 24036\n",
      "- Total words: 61196\n",
      "- Total accuracy: 39.27707693313288\n",
      "- Current GPU memory usage: 11155\n",
      "- Diff GPU memory usage: 8\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8900it [4:55:45,  1.99s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "8999it [4:59:10,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 9000\n",
      "- Total loss: 395.0504150390625\n",
      "- Total corrects: 24304\n",
      "- Total words: 61621\n",
      "- Total accuracy: 39.4410996251278\n",
      "- Current GPU memory usage: 11160\n",
      "- Diff GPU memory usage: 5\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9000it [4:59:22,  2.00s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "9099it [5:02:41,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 9100\n",
      "- Total loss: 396.9385070800781\n",
      "- Total corrects: 24133\n",
      "- Total words: 61670\n",
      "- Total accuracy: 39.132479325441864\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: -1130\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9100it [5:02:53,  2.00s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "9199it [5:06:06,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 9200\n",
      "- Total loss: 397.07769775390625\n",
      "- Total corrects: 24082\n",
      "- Total words: 62026\n",
      "- Total accuracy: 38.82565375810144\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9200it [5:06:19,  2.00s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "9299it [5:09:29,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 9300\n",
      "- Total loss: 398.537353515625\n",
      "- Total corrects: 24091\n",
      "- Total words: 61512\n",
      "- Total accuracy: 39.164715827805956\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9300it [5:09:41,  2.00s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "9399it [5:12:49,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 9400\n",
      "- Total loss: 391.1988830566406\n",
      "- Total corrects: 24513\n",
      "- Total words: 61862\n",
      "- Total accuracy: 39.62529501147716\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9400it [5:13:02,  2.00s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "9499it [5:16:18,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 9500\n",
      "- Total loss: 397.5958251953125\n",
      "- Total corrects: 23935\n",
      "- Total words: 61821\n",
      "- Total accuracy: 38.71661733068051\n",
      "- Current GPU memory usage: 11148\n",
      "- Diff GPU memory usage: 1118\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9500it [5:16:31,  2.00s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "9599it [5:19:58,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 9600\n",
      "- Total loss: 397.09033203125\n",
      "- Total corrects: 24189\n",
      "- Total words: 62039\n",
      "- Total accuracy: 38.9899901674753\n",
      "- Current GPU memory usage: 11132\n",
      "- Diff GPU memory usage: -16\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9600it [5:20:11,  2.00s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "9699it [5:23:33,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 9700\n",
      "- Total loss: 394.64031982421875\n",
      "- Total corrects: 24414\n",
      "- Total words: 61987\n",
      "- Total accuracy: 39.38567764208624\n",
      "- Current GPU memory usage: 11150\n",
      "- Diff GPU memory usage: 18\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9700it [5:23:46,  2.00s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "9799it [5:27:06,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 9800\n",
      "- Total loss: 387.709228515625\n",
      "- Total corrects: 24729\n",
      "- Total words: 61749\n",
      "- Total accuracy: 40.047612107078656\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: -1120\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9800it [5:27:18,  2.00s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "9899it [5:30:26,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 9900\n",
      "- Total loss: 385.8976135253906\n",
      "- Total corrects: 25193\n",
      "- Total words: 62058\n",
      "- Total accuracy: 40.59589416352444\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9900it [5:30:38,  2.00s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "9999it [5:33:46,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Save checkpoint to \"checkpoints/seq2seq_luong_2018-07-23 17:34:35_acc_39.63_loss_391.28_step_10000.pt\".\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 10000\n",
      "- Total loss: 391.282958984375\n",
      "- Total corrects: 24502\n",
      "- Total words: 61834\n",
      "- Total accuracy: 39.62544878222337\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [5:34:02,  2.00s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "10099it [5:37:09,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 10100\n",
      "- Total loss: 396.0757751464844\n",
      "- Total corrects: 24110\n",
      "- Total words: 61506\n",
      "- Total accuracy: 39.19942769811075\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10100it [5:37:22,  2.00s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "10199it [5:40:26,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 10200\n",
      "- Total loss: 400.138916015625\n",
      "- Total corrects: 23829\n",
      "- Total words: 61716\n",
      "- Total accuracy: 38.61073303519347\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10200it [5:40:38,  2.00s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "10299it [5:43:45,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 10300\n",
      "- Total loss: 389.0082092285156\n",
      "- Total corrects: 24494\n",
      "- Total words: 61258\n",
      "- Total accuracy: 39.984981553429755\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10300it [5:43:57,  2.00s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "10399it [5:47:06,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 10400\n",
      "- Total loss: 398.09271240234375\n",
      "- Total corrects: 24104\n",
      "- Total words: 62037\n",
      "- Total accuracy: 38.85423215178039\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10400it [5:47:18,  2.00s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "10499it [5:50:25,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 10500\n",
      "- Total loss: 388.79376220703125\n",
      "- Total corrects: 24779\n",
      "- Total words: 61689\n",
      "- Total accuracy: 40.16761497187505\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10500it [5:50:37,  2.00s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "10599it [5:54:01,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 10600\n",
      "- Total loss: 388.7762756347656\n",
      "- Total corrects: 24623\n",
      "- Total words: 61562\n",
      "- Total accuracy: 39.99707611838472\n",
      "- Current GPU memory usage: 11130\n",
      "- Diff GPU memory usage: 1100\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10600it [5:54:16,  2.01s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "10699it [5:57:49,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 10700\n",
      "- Total loss: 389.5329895019531\n",
      "- Total corrects: 24555\n",
      "- Total words: 61656\n",
      "- Total accuracy: 39.8258077072791\n",
      "- Current GPU memory usage: 11155\n",
      "- Diff GPU memory usage: 25\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10700it [5:58:02,  2.01s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "10799it [6:01:21,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 10800\n",
      "- Total loss: 389.8772888183594\n",
      "- Total corrects: 24729\n",
      "- Total words: 61801\n",
      "- Total accuracy: 40.01391563243313\n",
      "- Current GPU memory usage: 10578\n",
      "- Diff GPU memory usage: -577\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10800it [6:01:33,  2.01s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "10899it [6:04:54,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 10900\n",
      "- Total loss: 395.9747619628906\n",
      "- Total corrects: 24117\n",
      "- Total words: 61493\n",
      "- Total accuracy: 39.21909810872782\n",
      "- Current GPU memory usage: 10589\n",
      "- Diff GPU memory usage: 11\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10900it [6:05:06,  2.01s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "10999it [6:08:19,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 11000\n",
      "- Total loss: 388.12652587890625\n",
      "- Total corrects: 24622\n",
      "- Total words: 62043\n",
      "- Total accuracy: 39.68537949486646\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: -559\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11000it [6:08:31,  2.01s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "11099it [6:11:41,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 11100\n",
      "- Total loss: 390.1439208984375\n",
      "- Total corrects: 24565\n",
      "- Total words: 61527\n",
      "- Total accuracy: 39.925561135761534\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11100it [6:11:53,  2.01s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "11199it [6:15:00,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 11200\n",
      "- Total loss: 384.7684020996094\n",
      "- Total corrects: 24991\n",
      "- Total words: 61762\n",
      "- Total accuracy: 40.46339172954244\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11200it [6:15:12,  2.01s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "11299it [6:18:17,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 11300\n",
      "- Total loss: 388.92095947265625\n",
      "- Total corrects: 24475\n",
      "- Total words: 61420\n",
      "- Total accuracy: 39.848583523282315\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11300it [6:18:29,  2.01s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "11399it [6:21:37,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 11400\n",
      "- Total loss: 386.9617004394531\n",
      "- Total corrects: 24903\n",
      "- Total words: 61862\n",
      "- Total accuracy: 40.255730496912484\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11400it [6:21:49,  2.01s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "11499it [6:25:01,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 11500\n",
      "- Total loss: 390.0955505371094\n",
      "- Total corrects: 24745\n",
      "- Total words: 62440\n",
      "- Total accuracy: 39.630044843049326\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11500it [6:25:13,  2.01s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "11599it [6:28:18,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 11600\n",
      "- Total loss: 391.2621765136719\n",
      "- Total corrects: 24469\n",
      "- Total words: 61340\n",
      "- Total accuracy: 39.89077274209325\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11600it [6:28:30,  2.01s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "11699it [6:31:38,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 11700\n",
      "- Total loss: 391.6328125\n",
      "- Total corrects: 24376\n",
      "- Total words: 61558\n",
      "- Total accuracy: 39.598427499268986\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11700it [6:31:50,  2.01s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "11799it [6:34:54,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 11800\n",
      "- Total loss: 388.7408142089844\n",
      "- Total corrects: 24486\n",
      "- Total words: 60990\n",
      "- Total accuracy: 40.14756517461879\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11800it [6:35:06,  2.01s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "11899it [6:38:16,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 11900\n",
      "- Total loss: 390.62542724609375\n",
      "- Total corrects: 24542\n",
      "- Total words: 61560\n",
      "- Total accuracy: 39.86679662118259\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11900it [6:38:28,  2.01s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "11999it [6:41:32,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 12000\n",
      "- Total loss: 386.86175537109375\n",
      "- Total corrects: 24785\n",
      "- Total words: 61401\n",
      "- Total accuracy: 40.36579208807674\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12000it [6:41:45,  2.01s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "12099it [6:44:50,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 12100\n",
      "- Total loss: 391.1607971191406\n",
      "- Total corrects: 24384\n",
      "- Total words: 61427\n",
      "- Total accuracy: 39.69589919742133\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12100it [6:45:03,  2.01s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "12199it [6:48:12,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 12200\n",
      "- Total loss: 387.25201416015625\n",
      "- Total corrects: 24637\n",
      "- Total words: 61481\n",
      "- Total accuracy: 40.07254273678047\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12200it [6:48:24,  2.01s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "12299it [6:51:32,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 12300\n",
      "- Total loss: 388.6615295410156\n",
      "- Total corrects: 24701\n",
      "- Total words: 62065\n",
      "- Total accuracy: 39.79859824377668\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12300it [6:51:44,  2.01s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "12399it [6:54:52,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 12400\n",
      "- Total loss: 389.80792236328125\n",
      "- Total corrects: 24636\n",
      "- Total words: 61945\n",
      "- Total accuracy: 39.77076438776334\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12400it [6:55:05,  2.01s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "12499it [6:58:16,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 12500\n",
      "- Total loss: 383.7260437011719\n",
      "- Total corrects: 25279\n",
      "- Total words: 61768\n",
      "- Total accuracy: 40.925722056728404\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12500it [6:58:28,  2.01s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "12599it [7:01:34,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 12600\n",
      "- Total loss: 383.89276123046875\n",
      "- Total corrects: 24898\n",
      "- Total words: 61481\n",
      "- Total accuracy: 40.49706413363478\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12600it [7:01:46,  2.01s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "12699it [7:04:54,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 0/16\n",
      "- Global step: 12700\n",
      "- Total loss: 384.59912109375\n",
      "- Total corrects: 24940\n",
      "- Total words: 61550\n",
      "- Total accuracy: 40.519902518277824\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12700it [7:05:06,  2.01s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "12754it [7:06:50,  2.01s/it]\n",
      "45it [01:25,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 12800\n",
      "- Total loss: 382.62310791015625\n",
      "- Total corrects: 24709\n",
      "- Total words: 61650\n",
      "- Total accuracy: 40.07948094079481\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "46it [01:37,  2.13s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "145it [04:42,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 12900\n",
      "- Total loss: 375.4071350097656\n",
      "- Total corrects: 25104\n",
      "- Total words: 61420\n",
      "- Total accuracy: 40.87267990882449\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "146it [04:54,  2.01s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "245it [08:01,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 13000\n",
      "- Total loss: 376.6264343261719\n",
      "- Total corrects: 25090\n",
      "- Total words: 61493\n",
      "- Total accuracy: 40.80139202836095\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [08:12,  2.00s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "345it [11:19,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 13100\n",
      "- Total loss: 370.2427673339844\n",
      "- Total corrects: 25609\n",
      "- Total words: 61932\n",
      "- Total accuracy: 41.35019053155074\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "346it [11:31,  2.00s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "445it [14:37,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 13200\n",
      "- Total loss: 377.96185302734375\n",
      "- Total corrects: 25238\n",
      "- Total words: 61855\n",
      "- Total accuracy: 40.80187535364966\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "446it [14:48,  1.99s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "545it [17:56,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 13300\n",
      "- Total loss: 379.1913146972656\n",
      "- Total corrects: 24961\n",
      "- Total words: 61331\n",
      "- Total accuracy: 40.69883093378552\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "546it [18:07,  1.99s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "645it [21:15,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 13400\n",
      "- Total loss: 379.6500244140625\n",
      "- Total corrects: 24934\n",
      "- Total words: 61827\n",
      "- Total accuracy: 40.32865900011322\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "646it [21:26,  1.99s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "745it [24:34,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 13500\n",
      "- Total loss: 382.3374938964844\n",
      "- Total corrects: 24885\n",
      "- Total words: 62062\n",
      "- Total accuracy: 40.09699977441913\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "746it [24:45,  1.99s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "845it [27:50,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 13600\n",
      "- Total loss: 375.2095031738281\n",
      "- Total corrects: 25361\n",
      "- Total words: 61672\n",
      "- Total accuracy: 41.12238941496952\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "846it [28:01,  1.99s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "945it [31:09,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 13700\n",
      "- Total loss: 380.3502502441406\n",
      "- Total corrects: 25123\n",
      "- Total words: 62120\n",
      "- Total accuracy: 40.442691564713456\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "946it [31:20,  1.99s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "1045it [34:27,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 13800\n",
      "- Total loss: 375.9883728027344\n",
      "- Total corrects: 25163\n",
      "- Total words: 61503\n",
      "- Total accuracy: 40.913451376355624\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1046it [34:39,  1.99s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "1145it [37:44,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 13900\n",
      "- Total loss: 376.16534423828125\n",
      "- Total corrects: 25241\n",
      "- Total words: 61940\n",
      "- Total accuracy: 40.75072650952535\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1146it [37:56,  1.99s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "1245it [41:03,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 14000\n",
      "- Total loss: 377.227294921875\n",
      "- Total corrects: 25019\n",
      "- Total words: 61704\n",
      "- Total accuracy: 40.54680409697913\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1246it [41:15,  1.99s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "1345it [44:18,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 14100\n",
      "- Total loss: 377.41259765625\n",
      "- Total corrects: 24959\n",
      "- Total words: 61021\n",
      "- Total accuracy: 40.90231231870995\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1346it [44:29,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "1445it [47:36,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 14200\n",
      "- Total loss: 376.0614013671875\n",
      "- Total corrects: 25081\n",
      "- Total words: 61536\n",
      "- Total accuracy: 40.75825533021321\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1446it [47:47,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "1545it [50:54,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 14300\n",
      "- Total loss: 379.8453674316406\n",
      "- Total corrects: 24988\n",
      "- Total words: 61721\n",
      "- Total accuracy: 40.485410152136225\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1546it [51:06,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "1645it [54:13,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 14400\n",
      "- Total loss: 370.71099853515625\n",
      "- Total corrects: 25653\n",
      "- Total words: 61705\n",
      "- Total accuracy: 41.57361640061583\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1646it [54:24,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "1745it [57:28,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 14500\n",
      "- Total loss: 382.88507080078125\n",
      "- Total corrects: 24570\n",
      "- Total words: 61243\n",
      "- Total accuracy: 40.11887072808321\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1746it [57:40,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "1845it [1:00:47,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 14600\n",
      "- Total loss: 378.505126953125\n",
      "- Total corrects: 25146\n",
      "- Total words: 62145\n",
      "- Total accuracy: 40.46343229543809\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1846it [1:00:59,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "1945it [1:04:03,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 14700\n",
      "- Total loss: 379.5898742675781\n",
      "- Total corrects: 24916\n",
      "- Total words: 61449\n",
      "- Total accuracy: 40.547445849403566\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1946it [1:04:15,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "2045it [1:07:19,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 14800\n",
      "- Total loss: 375.6439514160156\n",
      "- Total corrects: 25334\n",
      "- Total words: 61724\n",
      "- Total accuracy: 41.04400233296611\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2046it [1:07:31,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "2145it [1:10:35,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 14900\n",
      "- Total loss: 380.0274963378906\n",
      "- Total corrects: 24960\n",
      "- Total words: 61093\n",
      "- Total accuracy: 40.85574452064885\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2146it [1:10:46,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "2245it [1:13:51,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Save checkpoint to \"checkpoints/seq2seq_luong_2018-07-23 17:34:35_acc_40.70_loss_379.43_step_15000.pt\".\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 15000\n",
      "- Total loss: 379.4288330078125\n",
      "- Total corrects: 25239\n",
      "- Total words: 62016\n",
      "- Total accuracy: 40.69756191950464\n",
      "- Current GPU memory usage: 10030\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2246it [1:14:08,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "2345it [1:17:14,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 15100\n",
      "- Total loss: 383.4288330078125\n",
      "- Total corrects: 24726\n",
      "- Total words: 61810\n",
      "- Total accuracy: 40.00323572237502\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: -8\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2346it [1:17:25,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "2445it [1:20:31,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 15200\n",
      "- Total loss: 378.8177795410156\n",
      "- Total corrects: 25256\n",
      "- Total words: 61905\n",
      "- Total accuracy: 40.79799693078103\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2446it [1:20:42,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "2545it [1:23:51,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 15300\n",
      "- Total loss: 377.61260986328125\n",
      "- Total corrects: 25232\n",
      "- Total words: 61849\n",
      "- Total accuracy: 40.796132516289674\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2546it [1:24:01,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "2645it [1:27:09,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 15400\n",
      "- Total loss: 379.6546630859375\n",
      "- Total corrects: 25064\n",
      "- Total words: 61652\n",
      "- Total accuracy: 40.653993382209826\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2646it [1:27:20,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "2745it [1:30:28,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 15500\n",
      "- Total loss: 381.68743896484375\n",
      "- Total corrects: 24849\n",
      "- Total words: 61651\n",
      "- Total accuracy: 40.30591555692527\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2746it [1:30:39,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "2845it [1:33:45,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 15600\n",
      "- Total loss: 377.5556945800781\n",
      "- Total corrects: 24828\n",
      "- Total words: 61289\n",
      "- Total accuracy: 40.50971626229829\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2846it [1:33:56,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "2945it [1:37:03,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 15700\n",
      "- Total loss: 383.7915954589844\n",
      "- Total corrects: 24815\n",
      "- Total words: 61953\n",
      "- Total accuracy: 40.05455748712734\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2946it [1:37:15,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "3045it [1:40:19,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 15800\n",
      "- Total loss: 379.59515380859375\n",
      "- Total corrects: 25154\n",
      "- Total words: 61521\n",
      "- Total accuracy: 40.88685164415403\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3046it [1:40:30,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "3145it [1:43:36,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 15900\n",
      "- Total loss: 381.86468505859375\n",
      "- Total corrects: 24897\n",
      "- Total words: 61612\n",
      "- Total accuracy: 40.40933584366682\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3146it [1:43:48,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "3245it [1:46:54,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 16000\n",
      "- Total loss: 374.7284851074219\n",
      "- Total corrects: 25443\n",
      "- Total words: 61938\n",
      "- Total accuracy: 41.07817494914269\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3246it [1:47:05,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "3345it [1:50:11,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 16100\n",
      "- Total loss: 376.4156799316406\n",
      "- Total corrects: 25262\n",
      "- Total words: 61851\n",
      "- Total accuracy: 40.84331700376712\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3346it [1:50:22,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "3445it [1:53:26,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 16200\n",
      "- Total loss: 374.53155517578125\n",
      "- Total corrects: 25208\n",
      "- Total words: 61348\n",
      "- Total accuracy: 41.09017408880485\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3446it [1:53:37,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "3545it [1:56:42,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 16300\n",
      "- Total loss: 378.994140625\n",
      "- Total corrects: 25036\n",
      "- Total words: 61664\n",
      "- Total accuracy: 40.60067462376751\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3546it [1:56:53,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "3645it [2:00:01,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 16400\n",
      "- Total loss: 380.4837341308594\n",
      "- Total corrects: 24958\n",
      "- Total words: 61708\n",
      "- Total accuracy: 40.445323134763726\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3646it [2:00:12,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "3745it [2:03:17,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 16500\n",
      "- Total loss: 371.5207214355469\n",
      "- Total corrects: 25798\n",
      "- Total words: 61798\n",
      "- Total accuracy: 41.74568756270429\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3746it [2:03:30,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "3845it [2:07:06,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 16600\n",
      "- Total loss: 377.4287414550781\n",
      "- Total corrects: 25250\n",
      "- Total words: 61589\n",
      "- Total accuracy: 40.99758073681989\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3846it [2:07:18,  1.99s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "3945it [2:10:28,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 16700\n",
      "- Total loss: 377.12286376953125\n",
      "- Total corrects: 25238\n",
      "- Total words: 62028\n",
      "- Total accuracy: 40.68807635261495\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3946it [2:10:39,  1.99s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "4045it [2:13:45,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 16800\n",
      "- Total loss: 375.2996520996094\n",
      "- Total corrects: 25785\n",
      "- Total words: 62035\n",
      "- Total accuracy: 41.56524542596921\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4046it [2:13:55,  1.99s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "4145it [2:16:59,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 16900\n",
      "- Total loss: 376.9834289550781\n",
      "- Total corrects: 25219\n",
      "- Total words: 61241\n",
      "- Total accuracy: 41.17992847928675\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4146it [2:17:10,  1.99s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "4245it [2:20:15,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 17000\n",
      "- Total loss: 379.73992919921875\n",
      "- Total corrects: 25197\n",
      "- Total words: 61790\n",
      "- Total accuracy: 40.778443113772454\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4246it [2:20:26,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "4345it [2:23:31,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 17100\n",
      "- Total loss: 373.95977783203125\n",
      "- Total corrects: 25287\n",
      "- Total words: 61706\n",
      "- Total accuracy: 40.97980747415163\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4346it [2:23:42,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "4445it [2:26:49,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 17200\n",
      "- Total loss: 379.17364501953125\n",
      "- Total corrects: 25223\n",
      "- Total words: 61907\n",
      "- Total accuracy: 40.74337312420243\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4446it [2:27:00,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "4545it [2:30:06,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 17300\n",
      "- Total loss: 370.720458984375\n",
      "- Total corrects: 25659\n",
      "- Total words: 61660\n",
      "- Total accuracy: 41.613687966266625\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4546it [2:30:18,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "4645it [2:33:27,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 17400\n",
      "- Total loss: 382.4952087402344\n",
      "- Total corrects: 24724\n",
      "- Total words: 61354\n",
      "- Total accuracy: 40.29729113016266\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4646it [2:33:39,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "4745it [2:36:45,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 17500\n",
      "- Total loss: 379.109619140625\n",
      "- Total corrects: 25115\n",
      "- Total words: 61620\n",
      "- Total accuracy: 40.757870821161966\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4746it [2:36:56,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "4845it [2:40:03,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 17600\n",
      "- Total loss: 377.808349609375\n",
      "- Total corrects: 25214\n",
      "- Total words: 61880\n",
      "- Total accuracy: 40.74660633484163\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4846it [2:40:14,  1.98s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "4945it [2:43:36,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 17700\n",
      "- Total loss: 375.1036071777344\n",
      "- Total corrects: 25370\n",
      "- Total words: 61697\n",
      "- Total accuracy: 41.120313791594405\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4946it [2:43:48,  1.99s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "5045it [2:47:05,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 17800\n",
      "- Total loss: 374.8848571777344\n",
      "- Total corrects: 25455\n",
      "- Total words: 61811\n",
      "- Total accuracy: 41.18199026063322\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5046it [2:47:16,  1.99s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "5145it [2:50:22,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 17900\n",
      "- Total loss: 375.6864929199219\n",
      "- Total corrects: 25171\n",
      "- Total words: 61380\n",
      "- Total accuracy: 41.008471814923425\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5146it [2:50:33,  1.99s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "5245it [2:53:39,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 18000\n",
      "- Total loss: 374.9314880371094\n",
      "- Total corrects: 25304\n",
      "- Total words: 61803\n",
      "- Total accuracy: 40.94299629467825\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5246it [2:53:51,  1.99s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "5345it [2:57:00,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 18100\n",
      "- Total loss: 379.1065979003906\n",
      "- Total corrects: 25286\n",
      "- Total words: 62172\n",
      "- Total accuracy: 40.67104162645564\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5346it [2:57:11,  1.99s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "5445it [3:00:19,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 18200\n",
      "- Total loss: 378.9352111816406\n",
      "- Total corrects: 25051\n",
      "- Total words: 62099\n",
      "- Total accuracy: 40.34042416141967\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5446it [3:00:30,  1.99s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "5545it [3:03:38,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 18300\n",
      "- Total loss: 380.1807556152344\n",
      "- Total corrects: 24814\n",
      "- Total words: 61612\n",
      "- Total accuracy: 40.274621826916835\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5546it [3:03:49,  1.99s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "5645it [3:06:55,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 18400\n",
      "- Total loss: 377.2500915527344\n",
      "- Total corrects: 25333\n",
      "- Total words: 61716\n",
      "- Total accuracy: 41.04770237863763\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5646it [3:07:06,  1.99s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "5745it [3:10:09,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 18500\n",
      "- Total loss: 374.5953369140625\n",
      "- Total corrects: 25261\n",
      "- Total words: 61240\n",
      "- Total accuracy: 41.249183540169824\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5746it [3:10:20,  1.99s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "5845it [3:13:26,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 18600\n",
      "- Total loss: 377.4834289550781\n",
      "- Total corrects: 25446\n",
      "- Total words: 62101\n",
      "- Total accuracy: 40.97518558477319\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5846it [3:13:38,  1.99s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "5945it [3:16:43,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 18700\n",
      "- Total loss: 376.032958984375\n",
      "- Total corrects: 25327\n",
      "- Total words: 61434\n",
      "- Total accuracy: 41.22635674056711\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5946it [3:16:53,  1.99s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "6045it [3:19:56,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 18800\n",
      "- Total loss: 369.6345520019531\n",
      "- Total corrects: 25576\n",
      "- Total words: 61231\n",
      "- Total accuracy: 41.76969182276951\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6046it [3:20:07,  1.99s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "6145it [3:23:13,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 18900\n",
      "- Total loss: 375.8845520019531\n",
      "- Total corrects: 25168\n",
      "- Total words: 61436\n",
      "- Total accuracy: 40.966208737548016\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6146it [3:23:24,  1.99s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "6245it [3:26:30,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 19000\n",
      "- Total loss: 374.0538330078125\n",
      "- Total corrects: 25242\n",
      "- Total words: 61859\n",
      "- Total accuracy: 40.80570329297273\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6246it [3:26:42,  1.99s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "6345it [3:29:52,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 19100\n",
      "- Total loss: 374.98736572265625\n",
      "- Total corrects: 25420\n",
      "- Total words: 62191\n",
      "- Total accuracy: 40.87408145873197\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6346it [3:30:03,  1.99s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "6445it [3:33:24,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 19200\n",
      "- Total loss: 378.53570556640625\n",
      "- Total corrects: 25266\n",
      "- Total words: 61703\n",
      "- Total accuracy: 40.94776591089575\n",
      "- Current GPU memory usage: 10578\n",
      "- Diff GPU memory usage: 556\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6446it [3:33:36,  1.99s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "6545it [3:36:52,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 19300\n",
      "- Total loss: 371.36065673828125\n",
      "- Total corrects: 25468\n",
      "- Total words: 61626\n",
      "- Total accuracy: 41.32671275111154\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: -556\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6546it [3:37:04,  1.99s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "6645it [3:40:19,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 19400\n",
      "- Total loss: 378.841552734375\n",
      "- Total corrects: 24979\n",
      "- Total words: 61855\n",
      "- Total accuracy: 40.38315415083664\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6646it [3:40:31,  1.99s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "6745it [3:43:35,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 19500\n",
      "- Total loss: 366.5566711425781\n",
      "- Total corrects: 25793\n",
      "- Total words: 61182\n",
      "- Total accuracy: 42.15782419665915\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6746it [3:43:46,  1.99s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "6845it [3:46:57,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 19600\n",
      "- Total loss: 378.7441101074219\n",
      "- Total corrects: 25255\n",
      "- Total words: 61725\n",
      "- Total accuracy: 40.91535034426894\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6846it [3:47:08,  1.99s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "6945it [3:50:31,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 19700\n",
      "- Total loss: 371.8826904296875\n",
      "- Total corrects: 25761\n",
      "- Total words: 62012\n",
      "- Total accuracy: 41.54195962071857\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6946it [3:50:43,  1.99s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "7045it [3:54:07,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 19800\n",
      "- Total loss: 365.3847961425781\n",
      "- Total corrects: 26125\n",
      "- Total words: 61713\n",
      "- Total accuracy: 42.33305786463144\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7046it [3:54:19,  2.00s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "7145it [3:57:42,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 19900\n",
      "- Total loss: 375.03167724609375\n",
      "- Total corrects: 25397\n",
      "- Total words: 61645\n",
      "- Total accuracy: 41.19879957823019\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7146it [3:57:54,  2.00s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "7245it [4:01:20,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Save checkpoint to \"checkpoints/seq2seq_luong_2018-07-23 17:34:35_acc_41.85_loss_370.17_step_20000.pt\".\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 20000\n",
      "- Total loss: 370.1744384765625\n",
      "- Total corrects: 26000\n",
      "- Total words: 62133\n",
      "- Total accuracy: 41.84571805642734\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7246it [4:01:36,  2.00s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "7345it [4:05:01,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 20100\n",
      "- Total loss: 372.6427001953125\n",
      "- Total corrects: 25592\n",
      "- Total words: 61947\n",
      "- Total accuracy: 41.31273507998773\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7346it [4:05:13,  2.00s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "7445it [4:08:36,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 20200\n",
      "- Total loss: 374.7507629394531\n",
      "- Total corrects: 25200\n",
      "- Total words: 61416\n",
      "- Total accuracy: 41.031652989449\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7446it [4:08:47,  2.00s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "7545it [4:12:11,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 20300\n",
      "- Total loss: 375.3673095703125\n",
      "- Total corrects: 25090\n",
      "- Total words: 61537\n",
      "- Total accuracy: 40.77221834018558\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7546it [4:12:22,  2.01s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "7645it [4:15:48,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 20400\n",
      "- Total loss: 372.5173034667969\n",
      "- Total corrects: 25447\n",
      "- Total words: 61693\n",
      "- Total accuracy: 41.24779148363672\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7646it [4:15:59,  2.01s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "7745it [4:19:23,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 20500\n",
      "- Total loss: 373.1775817871094\n",
      "- Total corrects: 25461\n",
      "- Total words: 61513\n",
      "- Total accuracy: 41.39125062994814\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7746it [4:19:34,  2.01s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "7845it [4:22:58,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 20600\n",
      "- Total loss: 372.9259033203125\n",
      "- Total corrects: 25822\n",
      "- Total words: 61898\n",
      "- Total accuracy: 41.71701832046269\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7846it [4:23:09,  2.01s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "7945it [4:26:33,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 20700\n",
      "- Total loss: 372.8350830078125\n",
      "- Total corrects: 25595\n",
      "- Total words: 61648\n",
      "- Total accuracy: 41.51797300804568\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7946it [4:26:44,  2.01s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "8045it [4:30:10,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 20800\n",
      "- Total loss: 371.0735778808594\n",
      "- Total corrects: 25853\n",
      "- Total words: 61962\n",
      "- Total accuracy: 41.723959846357445\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8046it [4:30:22,  2.02s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "8145it [4:33:43,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 20900\n",
      "- Total loss: 370.73358154296875\n",
      "- Total corrects: 25641\n",
      "- Total words: 61700\n",
      "- Total accuracy: 41.557536466774714\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8146it [4:33:54,  2.02s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "8245it [4:37:20,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 21000\n",
      "- Total loss: 382.37994384765625\n",
      "- Total corrects: 24606\n",
      "- Total words: 61775\n",
      "- Total accuracy: 39.831647106434644\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8246it [4:37:31,  2.02s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "8345it [4:40:54,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 21100\n",
      "- Total loss: 372.74365234375\n",
      "- Total corrects: 25478\n",
      "- Total words: 61434\n",
      "- Total accuracy: 41.47214897288147\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8346it [4:41:06,  2.02s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "8445it [4:44:29,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 21200\n",
      "- Total loss: 372.02618408203125\n",
      "- Total corrects: 25574\n",
      "- Total words: 62097\n",
      "- Total accuracy: 41.18395413627067\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8446it [4:44:41,  2.02s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "8545it [4:48:02,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 21300\n",
      "- Total loss: 376.8506774902344\n",
      "- Total corrects: 25445\n",
      "- Total words: 61800\n",
      "- Total accuracy: 41.17313915857605\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8546it [4:48:13,  2.02s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "8645it [4:51:35,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 21400\n",
      "- Total loss: 371.295166015625\n",
      "- Total corrects: 25583\n",
      "- Total words: 61309\n",
      "- Total accuracy: 41.727968161281375\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8646it [4:51:47,  2.02s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "8745it [4:55:12,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 21500\n",
      "- Total loss: 371.190673828125\n",
      "- Total corrects: 25788\n",
      "- Total words: 61891\n",
      "- Total accuracy: 41.66680131198397\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8746it [4:55:23,  2.03s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "8845it [4:58:49,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 21600\n",
      "- Total loss: 376.33734130859375\n",
      "- Total corrects: 25267\n",
      "- Total words: 61509\n",
      "- Total accuracy: 41.078541351672115\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8846it [4:59:00,  2.03s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "8945it [5:02:25,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 21700\n",
      "- Total loss: 369.9395751953125\n",
      "- Total corrects: 25502\n",
      "- Total words: 61937\n",
      "- Total accuracy: 41.17409625910199\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8946it [5:02:37,  2.03s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "9045it [5:06:02,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 21800\n",
      "- Total loss: 374.586669921875\n",
      "- Total corrects: 25441\n",
      "- Total words: 61679\n",
      "- Total accuracy: 41.24742619043759\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9046it [5:06:13,  2.03s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "9145it [5:09:33,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 21900\n",
      "- Total loss: 373.749755859375\n",
      "- Total corrects: 25562\n",
      "- Total words: 62051\n",
      "- Total accuracy: 41.19514592834926\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9146it [5:09:44,  2.03s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "9245it [5:13:08,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 22000\n",
      "- Total loss: 373.619873046875\n",
      "- Total corrects: 25287\n",
      "- Total words: 61515\n",
      "- Total accuracy: 41.10704706169227\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9246it [5:13:19,  2.03s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "9345it [5:16:43,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 22100\n",
      "- Total loss: 373.5039978027344\n",
      "- Total corrects: 25438\n",
      "- Total words: 61816\n",
      "- Total accuracy: 41.151158276174456\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9346it [5:16:54,  2.03s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "9445it [5:20:19,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 22200\n",
      "- Total loss: 371.264404296875\n",
      "- Total corrects: 25764\n",
      "- Total words: 61939\n",
      "- Total accuracy: 41.59576357383878\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9446it [5:20:30,  2.04s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "9545it [5:23:55,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 22300\n",
      "- Total loss: 370.22802734375\n",
      "- Total corrects: 25880\n",
      "- Total words: 61979\n",
      "- Total accuracy: 41.7560786718082\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9546it [5:24:07,  2.04s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "9645it [5:27:31,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 22400\n",
      "- Total loss: 370.9865417480469\n",
      "- Total corrects: 25586\n",
      "- Total words: 62011\n",
      "- Total accuracy: 41.26042153811421\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9646it [5:27:43,  2.04s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "9745it [5:31:08,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 22500\n",
      "- Total loss: 375.6183776855469\n",
      "- Total corrects: 25344\n",
      "- Total words: 61537\n",
      "- Total accuracy: 41.1849781432309\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9746it [5:31:20,  2.04s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "9845it [5:34:48,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 22600\n",
      "- Total loss: 371.5638732910156\n",
      "- Total corrects: 25842\n",
      "- Total words: 62085\n",
      "- Total accuracy: 41.623580575018124\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9846it [5:34:59,  2.04s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "9945it [5:38:24,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 22700\n",
      "- Total loss: 369.8229675292969\n",
      "- Total corrects: 25480\n",
      "- Total words: 61268\n",
      "- Total accuracy: 41.58777828556506\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9946it [5:38:36,  2.04s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "10045it [5:42:05,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 22800\n",
      "- Total loss: 378.09246826171875\n",
      "- Total corrects: 25093\n",
      "- Total words: 61841\n",
      "- Total accuracy: 40.57664009314209\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10046it [5:42:16,  2.04s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "10145it [5:45:44,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 22900\n",
      "- Total loss: 371.3936462402344\n",
      "- Total corrects: 25555\n",
      "- Total words: 61605\n",
      "- Total accuracy: 41.48202256310364\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10146it [5:45:55,  2.05s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "10245it [5:49:20,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 23000\n",
      "- Total loss: 369.5857849121094\n",
      "- Total corrects: 25677\n",
      "- Total words: 61080\n",
      "- Total accuracy: 42.03831041257368\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10246it [5:49:31,  2.05s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "10345it [5:53:00,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 23100\n",
      "- Total loss: 370.6978759765625\n",
      "- Total corrects: 25717\n",
      "- Total words: 61915\n",
      "- Total accuracy: 41.535976742308\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10346it [5:53:12,  2.05s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "10445it [5:56:39,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 23200\n",
      "- Total loss: 376.1422119140625\n",
      "- Total corrects: 25130\n",
      "- Total words: 61721\n",
      "- Total accuracy: 40.71547771423016\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10446it [5:56:51,  2.05s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "10545it [6:00:17,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 23300\n",
      "- Total loss: 370.15673828125\n",
      "- Total corrects: 25548\n",
      "- Total words: 61204\n",
      "- Total accuracy: 41.742369779752956\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10546it [6:00:29,  2.05s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "10645it [6:03:58,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 23400\n",
      "- Total loss: 372.6780700683594\n",
      "- Total corrects: 25472\n",
      "- Total words: 62013\n",
      "- Total accuracy: 41.075258413558444\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10646it [6:04:10,  2.05s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "10745it [6:07:38,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 23500\n",
      "- Total loss: 374.92974853515625\n",
      "- Total corrects: 25287\n",
      "- Total words: 61409\n",
      "- Total accuracy: 41.17800322428308\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10746it [6:07:49,  2.05s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "10845it [6:11:21,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 23600\n",
      "- Total loss: 373.6542053222656\n",
      "- Total corrects: 25247\n",
      "- Total words: 61468\n",
      "- Total accuracy: 41.07340404763454\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10846it [6:11:33,  2.06s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "10945it [6:15:05,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 23700\n",
      "- Total loss: 371.1973876953125\n",
      "- Total corrects: 25564\n",
      "- Total words: 61588\n",
      "- Total accuracy: 41.508085990777424\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10946it [6:15:16,  2.06s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "11045it [6:18:47,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 23800\n",
      "- Total loss: 371.1300354003906\n",
      "- Total corrects: 25427\n",
      "- Total words: 61436\n",
      "- Total accuracy: 41.387785663129115\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11046it [6:18:58,  2.06s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "11145it [6:22:30,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 23900\n",
      "- Total loss: 368.12432861328125\n",
      "- Total corrects: 25866\n",
      "- Total words: 61485\n",
      "- Total accuracy: 42.06879726762625\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11146it [6:22:41,  2.06s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "11245it [6:26:13,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 24000\n",
      "- Total loss: 370.11053466796875\n",
      "- Total corrects: 25712\n",
      "- Total words: 61791\n",
      "- Total accuracy: 41.61123788253953\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11246it [6:26:25,  2.06s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "11345it [6:29:49,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 24100\n",
      "- Total loss: 372.0287780761719\n",
      "- Total corrects: 25227\n",
      "- Total words: 61229\n",
      "- Total accuracy: 41.201064854889026\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11346it [6:30:01,  2.06s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "11445it [6:33:24,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 24200\n",
      "- Total loss: 371.1770324707031\n",
      "- Total corrects: 25773\n",
      "- Total words: 62223\n",
      "- Total accuracy: 41.420375102454074\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11446it [6:33:35,  2.06s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "11545it [6:37:08,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 24300\n",
      "- Total loss: 367.0928955078125\n",
      "- Total corrects: 25847\n",
      "- Total words: 61977\n",
      "- Total accuracy: 41.704180583119545\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11546it [6:37:20,  2.06s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "11645it [6:40:54,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 24400\n",
      "- Total loss: 367.89349365234375\n",
      "- Total corrects: 25711\n",
      "- Total words: 61884\n",
      "- Total accuracy: 41.54708810031672\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11646it [6:41:05,  2.07s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "11745it [6:44:36,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 24500\n",
      "- Total loss: 370.71966552734375\n",
      "- Total corrects: 25580\n",
      "- Total words: 61692\n",
      "- Total accuracy: 41.46404720223044\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11746it [6:44:47,  2.07s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "11845it [6:48:18,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 24600\n",
      "- Total loss: 364.2413635253906\n",
      "- Total corrects: 25873\n",
      "- Total words: 61479\n",
      "- Total accuracy: 42.08428894419233\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11846it [6:48:30,  2.07s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "11945it [6:52:02,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 24700\n",
      "- Total loss: 370.04119873046875\n",
      "- Total corrects: 25380\n",
      "- Total words: 61347\n",
      "- Total accuracy: 41.37121619639102\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11946it [6:52:13,  2.07s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "12045it [6:55:49,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 24800\n",
      "- Total loss: 369.1377868652344\n",
      "- Total corrects: 25664\n",
      "- Total words: 61849\n",
      "- Total accuracy: 41.49460783521156\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12046it [6:56:00,  2.07s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "12145it [6:59:33,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 24900\n",
      "- Total loss: 370.4532470703125\n",
      "- Total corrects: 25347\n",
      "- Total words: 61523\n",
      "- Total accuracy: 41.19922630560928\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12146it [6:59:45,  2.07s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "12245it [7:03:21,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Save checkpoint to \"checkpoints/seq2seq_luong_2018-07-23 17:34:35_acc_41.63_loss_369.99_step_25000.pt\".\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 25000\n",
      "- Total loss: 369.99176025390625\n",
      "- Total corrects: 25809\n",
      "- Total words: 61991\n",
      "- Total accuracy: 41.63346292203707\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12246it [7:03:36,  2.08s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "12345it [7:07:09,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 25100\n",
      "- Total loss: 368.4970397949219\n",
      "- Total corrects: 25517\n",
      "- Total words: 61254\n",
      "- Total accuracy: 41.65768766121396\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12346it [7:07:21,  2.08s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "12445it [7:10:54,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 25200\n",
      "- Total loss: 375.40966796875\n",
      "- Total corrects: 25370\n",
      "- Total words: 62109\n",
      "- Total accuracy: 40.84754222415431\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12446it [7:11:06,  2.08s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "12545it [7:14:42,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 25300\n",
      "- Total loss: 370.7822570800781\n",
      "- Total corrects: 25700\n",
      "- Total words: 61762\n",
      "- Total accuracy: 41.61134678281144\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12546it [7:14:54,  2.08s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "12645it [7:18:32,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 25400\n",
      "- Total loss: 363.5792541503906\n",
      "- Total corrects: 26284\n",
      "- Total words: 61890\n",
      "- Total accuracy: 42.46889642914849\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12646it [7:18:44,  2.08s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "12745it [7:22:18,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 1/16\n",
      "- Global step: 25500\n",
      "- Total loss: 368.6976318359375\n",
      "- Total corrects: 25802\n",
      "- Total words: 61507\n",
      "- Total accuracy: 41.949696782480046\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12746it [7:22:29,  2.08s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "12754it [7:22:47,  2.08s/it]\n",
      "91it [03:20,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 2/16\n",
      "- Global step: 25600\n",
      "- Total loss: 354.3841857910156\n",
      "- Total corrects: 26531\n",
      "- Total words: 62008\n",
      "- Total accuracy: 42.7864146561734\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "92it [03:31,  2.30s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "191it [07:11,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 2/16\n",
      "- Global step: 25700\n",
      "- Total loss: 356.704833984375\n",
      "- Total corrects: 26422\n",
      "- Total words: 62190\n",
      "- Total accuracy: 42.48593021386075\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192it [07:23,  2.31s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "291it [10:56,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 2/16\n",
      "- Global step: 25800\n",
      "- Total loss: 356.8683776855469\n",
      "- Total corrects: 26230\n",
      "- Total words: 62026\n",
      "- Total accuracy: 42.288717634540355\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "292it [11:07,  2.29s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "391it [14:46,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 2/16\n",
      "- Global step: 25900\n",
      "- Total loss: 359.8160400390625\n",
      "- Total corrects: 25982\n",
      "- Total words: 61773\n",
      "- Total accuracy: 42.06044712091043\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "392it [14:57,  2.29s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "491it [18:35,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 2/16\n",
      "- Global step: 26000\n",
      "- Total loss: 357.65435791015625\n",
      "- Total corrects: 25966\n",
      "- Total words: 61333\n",
      "- Total accuracy: 42.336099652715504\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "492it [18:46,  2.29s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "591it [22:25,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 2/16\n",
      "- Global step: 26100\n",
      "- Total loss: 359.2623596191406\n",
      "- Total corrects: 25973\n",
      "- Total words: 62068\n",
      "- Total accuracy: 41.846039827286205\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "592it [22:37,  2.29s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "691it [26:15,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 2/16\n",
      "- Global step: 26200\n",
      "- Total loss: 359.5369567871094\n",
      "- Total corrects: 26258\n",
      "- Total words: 61927\n",
      "- Total accuracy: 42.40153729391057\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "692it [26:27,  2.29s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "791it [30:05,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 2/16\n",
      "- Global step: 26300\n",
      "- Total loss: 360.0509033203125\n",
      "- Total corrects: 26239\n",
      "- Total words: 61789\n",
      "- Total accuracy: 42.46548738448591\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "792it [30:17,  2.29s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "891it [33:56,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 2/16\n",
      "- Global step: 26400\n",
      "- Total loss: 355.6280212402344\n",
      "- Total corrects: 26588\n",
      "- Total words: 62318\n",
      "- Total accuracy: 42.66504059822202\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "892it [34:08,  2.30s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "991it [37:43,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 2/16\n",
      "- Global step: 26500\n",
      "- Total loss: 363.2611999511719\n",
      "- Total corrects: 25260\n",
      "- Total words: 60946\n",
      "- Total accuracy: 41.44652643323598\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "992it [37:55,  2.29s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "1091it [41:32,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 2/16\n",
      "- Global step: 26600\n",
      "- Total loss: 363.79229736328125\n",
      "- Total corrects: 25558\n",
      "- Total words: 61847\n",
      "- Total accuracy: 41.324558992352095\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1092it [41:44,  2.29s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "1191it [45:18,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 2/16\n",
      "- Global step: 26700\n",
      "- Total loss: 366.0101318359375\n",
      "- Total corrects: 25461\n",
      "- Total words: 61123\n",
      "- Total accuracy: 41.65535068632102\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1192it [45:29,  2.29s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "1291it [49:06,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 2/16\n",
      "- Global step: 26800\n",
      "- Total loss: 356.6783752441406\n",
      "- Total corrects: 26258\n",
      "- Total words: 61650\n",
      "- Total accuracy: 42.59205190592052\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1292it [49:17,  2.29s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "1391it [52:55,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 2/16\n",
      "- Global step: 26900\n",
      "- Total loss: 358.9457092285156\n",
      "- Total corrects: 26178\n",
      "- Total words: 61578\n",
      "- Total accuracy: 42.511936081067915\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1392it [53:06,  2.29s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "1491it [56:42,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 2/16\n",
      "- Global step: 27000\n",
      "- Total loss: 361.9019775390625\n",
      "- Total corrects: 26058\n",
      "- Total words: 61820\n",
      "- Total accuracy: 42.15140731154966\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1492it [56:53,  2.29s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "1591it [1:00:32,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 2/16\n",
      "- Global step: 27100\n",
      "- Total loss: 363.99298095703125\n",
      "- Total corrects: 26192\n",
      "- Total words: 62556\n",
      "- Total accuracy: 41.86968476245284\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1592it [1:00:43,  2.29s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "1691it [1:04:20,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 2/16\n",
      "- Global step: 27200\n",
      "- Total loss: 365.39178466796875\n",
      "- Total corrects: 25722\n",
      "- Total words: 61680\n",
      "- Total accuracy: 41.702334630350194\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1692it [1:04:31,  2.29s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "1791it [1:08:11,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 2/16\n",
      "- Global step: 27300\n",
      "- Total loss: 361.525146484375\n",
      "- Total corrects: 25887\n",
      "- Total words: 61514\n",
      "- Total accuracy: 42.0831030334558\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1792it [1:08:23,  2.29s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "1891it [1:11:57,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 2/16\n",
      "- Global step: 27400\n",
      "- Total loss: 358.0492248535156\n",
      "- Total corrects: 25939\n",
      "- Total words: 61240\n",
      "- Total accuracy: 42.35630306988896\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1892it [1:12:08,  2.29s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "1991it [1:15:43,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 2/16\n",
      "- Global step: 27500\n",
      "- Total loss: 360.7436828613281\n",
      "- Total corrects: 25675\n",
      "- Total words: 61429\n",
      "- Total accuracy: 41.79622002637191\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1992it [1:15:54,  2.29s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "2091it [1:19:29,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 2/16\n",
      "- Global step: 27600\n",
      "- Total loss: 363.4473571777344\n",
      "- Total corrects: 25732\n",
      "- Total words: 61303\n",
      "- Total accuracy: 41.97510725413112\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2092it [1:19:41,  2.29s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "2191it [1:23:15,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 2/16\n",
      "- Global step: 27700\n",
      "- Total loss: 367.9173583984375\n",
      "- Total corrects: 25553\n",
      "- Total words: 61983\n",
      "- Total accuracy: 41.225819982898535\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2192it [1:23:27,  2.28s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "2291it [1:27:05,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 2/16\n",
      "- Global step: 27800\n",
      "- Total loss: 365.2875671386719\n",
      "- Total corrects: 25700\n",
      "- Total words: 61668\n",
      "- Total accuracy: 41.674774599468115\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2292it [1:27:16,  2.28s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "2391it [1:30:57,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 2/16\n",
      "- Global step: 27900\n",
      "- Total loss: 361.7564697265625\n",
      "- Total corrects: 26461\n",
      "- Total words: 62276\n",
      "- Total accuracy: 42.489883743336115\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2392it [1:31:08,  2.29s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "2491it [1:34:43,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 2/16\n",
      "- Global step: 28000\n",
      "- Total loss: 362.59173583984375\n",
      "- Total corrects: 25791\n",
      "- Total words: 61805\n",
      "- Total accuracy: 41.72963352479573\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2492it [1:34:54,  2.29s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "2591it [1:38:31,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 2/16\n",
      "- Global step: 28100\n",
      "- Total loss: 366.02581787109375\n",
      "- Total corrects: 25285\n",
      "- Total words: 61069\n",
      "- Total accuracy: 41.40398565556993\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2592it [1:38:42,  2.28s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "2691it [1:42:19,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 2/16\n",
      "- Global step: 28200\n",
      "- Total loss: 361.1585388183594\n",
      "- Total corrects: 26008\n",
      "- Total words: 62001\n",
      "- Total accuracy: 41.947710520798054\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2692it [1:42:30,  2.28s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "2791it [1:46:06,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 2/16\n",
      "- Global step: 28300\n",
      "- Total loss: 364.54473876953125\n",
      "- Total corrects: 25748\n",
      "- Total words: 61499\n",
      "- Total accuracy: 41.86734743654368\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2792it [1:46:18,  2.28s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "2891it [1:49:53,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 2/16\n",
      "- Global step: 28400\n",
      "- Total loss: 361.1319885253906\n",
      "- Total corrects: 26125\n",
      "- Total words: 61795\n",
      "- Total accuracy: 42.27688324298082\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2892it [1:50:04,  2.28s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "2991it [1:53:40,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 2/16\n",
      "- Global step: 28500\n",
      "- Total loss: 362.7101745605469\n",
      "- Total corrects: 25928\n",
      "- Total words: 61589\n",
      "- Total accuracy: 42.098426667099645\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2992it [1:53:51,  2.28s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "3091it [1:57:25,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 2/16\n",
      "- Global step: 28600\n",
      "- Total loss: 360.3674011230469\n",
      "- Total corrects: 26131\n",
      "- Total words: 61881\n",
      "- Total accuracy: 42.22782437258609\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3092it [1:57:36,  2.28s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "3191it [2:01:13,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 2/16\n",
      "- Global step: 28700\n",
      "- Total loss: 359.3320617675781\n",
      "- Total corrects: 26186\n",
      "- Total words: 61507\n",
      "- Total accuracy: 42.57401596566244\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3192it [2:01:24,  2.28s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "3291it [2:05:00,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Training log:\n",
      "- Epoch: 2/16\n",
      "- Global step: 28800\n",
      "- Total loss: 358.36663818359375\n",
      "- Total corrects: 26426\n",
      "- Total words: 61644\n",
      "- Total accuracy: 42.868730127830766\n",
      "- Current GPU memory usage: 10022\n",
      "- Diff GPU memory usage: 0\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3292it [2:05:12,  2.28s/it]/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:115: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/afs/inf.ed.ac.uk/user/s04/s0451365/miniconda3/envs/jgrace1/lib/python3.5/site-packages/ipykernel/__main__.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "3371it [2:08:05,  2.28s/it]"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for batch_id, batch_data in tqdm(enumerate(train_iter)):\n",
    "\n",
    "        # Unpack batch data\n",
    "        src_sents, tgt_sents, src_seqs, tgt_seqs, src_lens, tgt_lens = batch_data\n",
    "        \n",
    "        # Ignore batch if there is a long sequence.\n",
    "        max_seq_len = max(src_lens + tgt_lens)\n",
    "        if max_seq_len > opts.max_seq_len:\n",
    "            print('[!] Ignore batch: sequence length={} > max sequence length={}'.format(max_seq_len, opts.max_seq_len))\n",
    "            continue\n",
    "        \n",
    "        # Train.\n",
    "        loss, pred_seqs, attention_weights, num_corrects, num_words, \\\n",
    "        encoder_grad_norm, decoder_grad_norm, clipped_encoder_grad_norm, clipped_decoder_grad_norm \\\n",
    "        = train(src_sents, tgt_sents, src_seqs, tgt_seqs, src_lens, tgt_lens, encoder, decoder, encoder_optim, decoder_optim, opts)\n",
    "\n",
    "        # Statistics.\n",
    "        global_step += 1\n",
    "        total_loss += loss\n",
    "        total_corrects += num_corrects\n",
    "        total_words += num_words\n",
    "        total_accuracy = 100 * (total_corrects / total_words.item())\n",
    "        \n",
    "        # Save checkpoint.\n",
    "        if global_step % save_every_step == 0:\n",
    "            \n",
    "            checkpoint_path = save_checkpoint(opts, experiment_name, encoder, decoder, encoder_optim, decoder_optim, \n",
    "                                              total_accuracy, total_loss, global_step)\n",
    "            \n",
    "            print('='*100)\n",
    "            print('Save checkpoint to \"{}\".'.format(checkpoint_path))\n",
    "            print('='*100 + '\\n')\n",
    "\n",
    "        # Print statistics and write to Tensorboard.\n",
    "        if global_step % print_every_step == 0:\n",
    "            \n",
    "            curr_gpu_memory_usage = get_gpu_memory_usage(device_id=torch.cuda.current_device())\n",
    "            diff_gpu_memory_usage = curr_gpu_memory_usage - prev_gpu_memory_usage\n",
    "            prev_gpu_memory_usage = curr_gpu_memory_usage\n",
    "            \n",
    "            print('='*100)\n",
    "            print('Training log:')\n",
    "            print('- Epoch: {}/{}'.format(epoch, num_epochs))\n",
    "            print('- Global step: {}'.format(global_step))\n",
    "            print('- Total loss: {}'.format(total_loss))\n",
    "            print('- Total corrects: {}'.format(total_corrects))\n",
    "            print('- Total words: {}'.format(total_words))\n",
    "            print('- Total accuracy: {}'.format(total_accuracy))\n",
    "            print('- Current GPU memory usage: {}'.format(curr_gpu_memory_usage))\n",
    "            print('- Diff GPU memory usage: {}'.format(diff_gpu_memory_usage))\n",
    "            print('='*100 + '\\n')\n",
    "            \n",
    "            write_to_tensorboard(writer, global_step, total_loss, total_corrects, total_words, total_accuracy,\n",
    "                                 encoder_grad_norm, decoder_grad_norm, clipped_encoder_grad_norm, clipped_decoder_grad_norm,\n",
    "                                 encoder, decoder,\n",
    "                                 gpu_memory_usage={\n",
    "                                     'curr': curr_gpu_memory_usage,\n",
    "                                     'diff': diff_gpu_memory_usage\n",
    "                                 })\n",
    "            \n",
    "            total_loss = 0\n",
    "            total_corrects = 0\n",
    "            total_words = 0\n",
    "\n",
    "        # Free memory\n",
    "        del src_sents, tgt_sents, src_seqs, tgt_seqs, src_lens, tgt_lens, \\\n",
    "            loss, pred_seqs, attention_weights, num_corrects, num_words, \\\n",
    "            encoder_grad_norm, decoder_grad_norm, clipped_encoder_grad_norm, clipped_decoder_grad_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = save_checkpoint(opts, experiment_name, encoder, decoder, encoder_optim, decoder_optim, \n",
    "                                              total_accuracy, total_loss, global_step)\n",
    "            \n",
    "print('='*100)\n",
    "print('Save checkpoint to \"{}\".'.format(checkpoint_path))\n",
    "print('='*100 + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(src_sents, tgt_sents, src_seqs, tgt_seqs, src_lens, tgt_lens, encoder, decoder):\n",
    "    # -------------------------------------\n",
    "    # Prepare input and output placeholders\n",
    "    # -------------------------------------\n",
    "    # Last batch might not have the same size as we set to the `batch_size`\n",
    "    batch_size = src_seqs.size(1)\n",
    "    assert(batch_size == tgt_seqs.size(1))\n",
    "    \n",
    "    # Pack tensors to variables for neural network inputs (in order to autograd)\n",
    "    src_seqs = Variable(src_seqs, volatile=True)\n",
    "    tgt_seqs = Variable(tgt_seqs, volatile=True)\n",
    "    src_lens = Variable(torch.LongTensor(src_lens), volatile=True)\n",
    "    tgt_lens = Variable(torch.LongTensor(tgt_lens), volatile=True)\n",
    "\n",
    "    # Decoder's input\n",
    "    input_seq = Variable(torch.LongTensor([BOS] * batch_size), volatile=True)\n",
    "    \n",
    "    # Decoder's output sequence length = max target sequence length of current batch.\n",
    "    max_tgt_len = tgt_lens.data.max()\n",
    "    \n",
    "    # Store all decoder's outputs.\n",
    "    # **CRUTIAL** \n",
    "    # Don't set:\n",
    "    # >> decoder_outputs = Variable(torch.zeros(max_tgt_len, batch_size, decoder.vocab_size))\n",
    "    # Varying tensor size could cause GPU allocate a new memory causing OOM, \n",
    "    # so we intialize tensor with fixed size instead:\n",
    "    # `opts.max_seq_len` is a fixed number, unlike `max_tgt_len` always varys.\n",
    "    decoder_outputs = Variable(torch.zeros(opts.max_seq_len, batch_size, decoder.vocab_size), volatile=True)\n",
    "\n",
    "    # Move variables from CPU to GPU.\n",
    "    if USE_CUDA:\n",
    "        src_seqs = src_seqs.cuda()\n",
    "        tgt_seqs = tgt_seqs.cuda()\n",
    "        src_lens = src_lens.cuda()\n",
    "        tgt_lens = tgt_lens.cuda()\n",
    "        input_seq = input_seq.cuda()\n",
    "        decoder_outputs = decoder_outputs.cuda()\n",
    "        \n",
    "    # -------------------------------------\n",
    "    # Evaluation mode (disable dropout)\n",
    "    # -------------------------------------\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "            \n",
    "    # -------------------------------------\n",
    "    # Forward encoder\n",
    "    # -------------------------------------\n",
    "    encoder_outputs, encoder_hidden = encoder(src_seqs, src_lens.data.tolist())\n",
    "    \n",
    "    # -------------------------------------\n",
    "    # Forward decoder\n",
    "    # -------------------------------------\n",
    "    # Initialize decoder's hidden state as encoder's last hidden state.\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    # Run through decoder one time step at a time.\n",
    "    for t in range(max_tgt_len):\n",
    "        \n",
    "        # decoder returns:\n",
    "        # - decoder_output   : (batch_size, vocab_size)\n",
    "        # - decoder_hidden   : (num_layers, batch_size, hidden_size)\n",
    "        # - attention_weights: (batch_size, max_src_len)\n",
    "        decoder_output, decoder_hidden, attention_weights = decoder(input_seq, decoder_hidden,\n",
    "                                                                    encoder_outputs, src_lens)\n",
    "\n",
    "        # Store decoder outputs.\n",
    "        decoder_outputs[t] = decoder_output\n",
    "        \n",
    "        # Next input is current target\n",
    "        input_seq = tgt_seqs[t]\n",
    "        \n",
    "        # Detach hidden state (may not need this, since no BPTT)\n",
    "        detach_hidden(decoder_hidden)\n",
    "        \n",
    "    # -------------------------------------\n",
    "    # Compute loss\n",
    "    # -------------------------------------\n",
    "    loss, pred_seqs, num_corrects, num_words = masked_cross_entropy(\n",
    "        decoder_outputs[:max_tgt_len].transpose(0,1).contiguous(), \n",
    "        tgt_seqs.transpose(0,1).contiguous(),\n",
    "        tgt_lens\n",
    "    )\n",
    "    \n",
    "    pred_seqs = pred_seqs[:max_tgt_len]\n",
    "    \n",
    "    return loss.data[0], pred_seqs, attention_weights, num_corrects, num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss = 0\n",
    "total_corrects = 0\n",
    "total_words = 0\n",
    "\n",
    "for batch_id, batch_data in tqdm(enumerate(valid_iter)):\n",
    "    src_sents, tgt_sents, src_seqs, tgt_seqs, src_lens, tgt_lens = batch_data\n",
    "    \n",
    "    loss, pred_seqs, attention_weights, num_corrects, num_words \\\n",
    "        = evaluate(src_sents, tgt_sents, src_seqs, tgt_seqs, src_lens, tgt_lens, encoder, decoder)\n",
    "        \n",
    "    total_loss += loss\n",
    "    total_corrects += num_corrects\n",
    "    total_words += num_words\n",
    "    total_accuracy = 100 * (total_corrects / total_words)\n",
    "\n",
    "print('='*100)\n",
    "print('Validation log:')\n",
    "print('- Total loss: {}'.format(total_loss))\n",
    "print('- Total corrects: {}'.format(total_corrects))\n",
    "print('- Total words: {}'.format(total_words))\n",
    "print('- Total accuracy: {}'.format(total_accuracy))\n",
    "print('='*100 + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate (inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(src_text, train_dataset, encoder, decoder, max_seq_len, replace_unk=True):\n",
    "    # -------------------------------------\n",
    "    # Prepare input and output placeholders\n",
    "    # -------------------------------------\n",
    "    # Like dataset's `__getitem__()` and dataloader's `collate_fn()`.\n",
    "    src_sent = src_text.split()\n",
    "    src_seqs = torch.LongTensor([train_dataset.tokens2ids(tokens=src_text.split(),\n",
    "                                                          token2id=train_dataset.src_vocab.token2id,\n",
    "                                                          append_BOS=False, append_EOS=True)]).transpose(0,1)\n",
    "    src_lens = [len(src_seqs)]\n",
    "    \n",
    "    # Last batch might not have the same size as we set to the `batch_size`\n",
    "    batch_size = src_seqs.size(1)\n",
    "    \n",
    "    # Pack tensors to variables for neural network inputs (in order to autograd)\n",
    "    src_seqs = Variable(src_seqs, volatile=True)\n",
    "    src_lens = Variable(torch.LongTensor(src_lens), volatile=True)\n",
    "\n",
    "    # Decoder's input\n",
    "    input_seq = Variable(torch.LongTensor([BOS] * batch_size), volatile=True)\n",
    "    # Store output words and attention states\n",
    "    out_sent = []\n",
    "    all_attention_weights = torch.zeros(max_seq_len, len(src_seqs))\n",
    "    \n",
    "    # Move variables from CPU to GPU.\n",
    "    if USE_CUDA:\n",
    "        src_seqs = src_seqs.cuda()\n",
    "        src_lens = src_lens.cuda()\n",
    "        input_seq = input_seq.cuda()\n",
    "        \n",
    "    # -------------------------------------\n",
    "    # Evaluation mode (disable dropout)\n",
    "    # -------------------------------------\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "        \n",
    "    # -------------------------------------\n",
    "    # Forward encoder\n",
    "    # -------------------------------------\n",
    "    encoder_outputs, encoder_hidden = encoder(src_seqs, src_lens.data.tolist())\n",
    "\n",
    "    # -------------------------------------\n",
    "    # Forward decoder\n",
    "    # -------------------------------------\n",
    "    # Initialize decoder's hidden state as encoder's last hidden state.\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    # Run through decoder one time step at a time.\n",
    "    for t in range(max_seq_len):\n",
    "        \n",
    "        # decoder returns:\n",
    "        # - decoder_output   : (batch_size, vocab_size)\n",
    "        # - decoder_hidden   : (num_layers, batch_size, hidden_size)\n",
    "        # - attention_weights: (batch_size, max_src_len)\n",
    "        decoder_output, decoder_hidden, attention_weights = decoder(input_seq, decoder_hidden,\n",
    "                                                                    encoder_outputs, src_lens)\n",
    "\n",
    "        # Store attention weights.\n",
    "        # .squeeze(0): remove `batch_size` dimension since batch_size=1\n",
    "        all_attention_weights[t] = attention_weights.squeeze(0).cpu().data \n",
    "        \n",
    "        # Choose top word from decoder's output\n",
    "        prob, token_id = decoder_output.data.topk(1)\n",
    "        token_id = token_id[0][0] # get value\n",
    "        if token_id == EOS:\n",
    "            break\n",
    "        else:\n",
    "            if token_id == UNK and replace_unk:\n",
    "                # Replace unk by selecting the source token with the highest attention score.\n",
    "                score, idx = all_attention_weights[t].max(0)\n",
    "                token = src_sent[idx[0]]\n",
    "            else:\n",
    "                # <UNK>\n",
    "                token = train_dataset.tgt_vocab.id2token[token_id]\n",
    "            \n",
    "            out_sent.append(token)\n",
    "        \n",
    "        # Next input is chosen word\n",
    "        input_seq = Variable(torch.LongTensor([token_id]), volatile=True)\n",
    "        if USE_CUDA: input_seq = input_seq.cuda()\n",
    "            \n",
    "        # Repackage hidden state (may not need this, since no BPTT)\n",
    "        detach_hidden(decoder_hidden)\n",
    "    \n",
    "    src_text = ' '.join([train_dataset.src_vocab.id2token[token_id] for token_id in src_seqs.data.squeeze(1).tolist()])\n",
    "    out_text = ' '.join(out_sent)\n",
    "        \n",
    "    # all_attention_weights: (out_len, src_len)\n",
    "    return src_text, out_text, all_attention_weights[:len(out_sent)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_text, out_text, all_attention_weights = translate('He have a car', train_dataset, encoder, decoder, max_seq_len=opts.max_seq_len)\n",
    "src_text, out_text, all_attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# check attention weight sum == 1# check \n",
    "[all_attention_weights[t].sum() for t in range(all_attention_weights.size(0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jgrace1]",
   "language": "python",
   "name": "conda-env-jgrace1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
